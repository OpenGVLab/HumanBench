out_dir: /mnt/lustrenew/chencheng1/expr_files/vitruvian/devL2/L2_samll_setting_parsing_FT

common:  # prefix
  project_name: L2_samll_setting_parsing_FT
  model_entry_type: backbone_aio_entry
  solver:
    type: SolverMultiTaskDev

  lr_scheduler:
    type: 'WarmupCosine'
    kwargs:
      base_lr: 5e-4
      warmup_factor: 0.01
      warmup_iters: 1500
      warmup_method: linear

  backbone_multiplier: 0.8
  optimizer:
    type: AdamWWithBackboneClipDev
    kwargs:
      clip_norm: 0.01
      norm_type: 2
      betas: [0.9, 0.999]
      weight_decay: 0.1

  layer_decay:
    # layer decay
    num_layers: 12
    layer_decay_rate: 0.75
    lpe_lr: True
      
  auto_denan: False

  workers: 2
  max_iter: 22100 # 20ep 4card 17706 images  / (20 * 17706) / (4 * 4)

  deterministic: True   # seed control
  cudnn_deterministic: False
  worker_rank: True
  random_seed: 42

  print_freq: 10
  vis_batch: False
  save_interval: 30000

  use_ceph: True
  sync: True

# task_specific_param = ['backbone', 'neck', 'decoder', 'dataset', 'sampler', 'lr_scheduler', 'optimizer']
tasks :  # prefix
  0:     # prefix
    name: ATR_parsing
    loss_weight: 1.0
    gres_ratio: 1  # int, > 0, = Task_GPUs / (world_Size/sum(all_gres_ratios))
    backbone:
      type: vit_base_patch16
      kwargs:
        task_sp_list: ['pos_embed', 'rel_pos_h', 'rel_pos_w'] # wrong list would somehow cause .cuda() stuck without error
        pretrained: True
        pretrain_path: '/mnt/lustre/chencheng1/expr_files/vitruvian/devL2/transed_ckpt_for_pretrain/devL2_small_setting/parsing/vitbase_lr1e3_StepLRx3_backboneclip_bmp08_ld75_pose_dpr03_dcLN_par_dpr03_dcBN_attr_dpr01_reid_clstoken_dpr0_LSA_10p_small_setting6_add_posetrack_DGMarket_deepfashion.pth'
        load_pos_embed: True
        pos_embed_interp: False
        learnable_pos: True
        window: False
        drop_path_rate: 0.3
        img_size: 480
    
    dataset:
      type: ATRParsingDataset
      kwargs:
        data_path: /mnt/lustrenew/share_data/viface/vitruvian/L1_benchmark/human_parsing/ATR # files in core/data/datasets/images/resources/* or absolute path
        cfg:
          is_flip: True
          crop_size: [480, 480]
          is_multi_scale: True
          scale_factor: 11
          center_crop_test: False
          base_size: 480
#          mean: [0.485, 0.456, 0.406]
#          std: [0.229, 0.224, 0.225]
          eval_crop_size: [480, 480]

          ####
          ignore_value: 255 # duplicated with decoder.kwargs.ignore_value
          num_classes: 18
          label_list: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,]
#          reduce_zero_label: True

    sampler:
      batch_size: 4  # per card
      shuffle_strategy: 1
    
    neck:
      type: DoNothing
      kwargs: {}

    decoder:  # todo: coco instance seg config for now
      type: ViT_SimpleUpSampling
      kwargs:
        task: par
        input_size: [480,480]
        in_channels: 768
        num_classes: 18
        bn_type: torchbn
        loss_cfg:
          type: FSCELoss
          kwargs:
            configer:
              ce_reduction: elementwise_mean
              ce_ignore_index: 255