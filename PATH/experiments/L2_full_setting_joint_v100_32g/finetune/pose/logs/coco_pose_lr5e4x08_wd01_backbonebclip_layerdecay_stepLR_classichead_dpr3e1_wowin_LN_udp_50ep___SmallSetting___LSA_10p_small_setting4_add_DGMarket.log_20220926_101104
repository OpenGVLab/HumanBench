phoenix-srun: Job 88804 scheduled successfully!
Current QUOTA_TYPE is [reserved], which means the job has occupied quota in RESERVED_TOTAL under your partition.
Current PHX_PRIORITY is P0

[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[rank 0000]-[INFO]-[c13d]-[2022-09-26 10:06:14]-[/spring/src/linklink/src/core.cc:220]: linklink init: world_size=4, rank=(0,0), device_num=1, thread_pool=1, buffer_pool=-1
[rank 0001]-[INFO]-[d30b]-[2022-09-26 10:06:14]-[/spring/src/linklink/src/core.cc:220]: linklink init: world_size=4, rank=(1,1), device_num=1, thread_pool=1, buffer_pool=-1
[rank 0002]-[INFO]-[adbf]-[2022-09-26 10:06:14]-[/spring/src/linklink/src/core.cc:220]: linklink init: world_size=4, rank=(2,2), device_num=1, thread_pool=1, buffer_pool=-1
[rank 0003]-[INFO]-[3b5c]-[2022-09-26 10:06:14]-[/spring/src/linklink/src/core.cc:220]: linklink init: world_size=4, rank=(3,3), device_num=1, thread_pool=1, buffer_pool=-1
[rank 0] >> task_info.group[0] ranks [0, 1, 2, 3]
[rank 3] >> task_info.group[0] ranks [0, 1, 2, 3]
[rank 2] >> task_info.group[0] ranks [0, 1, 2, 3]
[rank 1] >> task_info.group[0] ranks [0, 1, 2, 3]
[rank 1] >> task_info.root_group ranks [0]
[rank 3] >> task_info.root_group ranks [0]
[rank 2] >> task_info.root_group ranks [0]
[rank 0] >> task_info.root_group ranks [0]
[rank 0] >> task_info.backbone_share_group[[0]] ranks [0, 1, 2, 3]
[rank 3] >> task_info.backbone_share_group[[0]] ranks [0, 1, 2, 3]
[rank 1] >> task_info.backbone_share_group[[0]] ranks [0, 1, 2, 3]
[rank 2] >> task_info.backbone_share_group[[0]] ranks [0, 1, 2, 3]
[rank 3] >> task_info.neck_share_group[[0]] ranks [0, 1, 2, 3]
[rank 0] >> task_info.neck_share_group[[0]] ranks [0, 1, 2, 3]
[rank 2] >> task_info.neck_share_group[[0]] ranks [0, 1, 2, 3]
[rank 1] >> task_info.neck_share_group[[0]] ranks [0, 1, 2, 3]
[rank 3] >> task_info.decoder_share_group[[0]] ranks [0, 1, 2, 3]
[rank 3] neck of task0 has been overided to {'type': 'DoNothing', 'kwargs': {'backbone': 'None'}}
[rank 3] decoder of task0 has been overided to {'type': 'TopDownSimpleHead', 'kwargs': {'layer_norm': True, 'use_sync_bn': False, 'bn_sync_stats': False, 'in_channels': 768, 'out_channels': 17, 'num_deconv_layers': 2, 'num_deconv_filters': [256, 256], 'num_deconv_kernels': [4, 4], 'upsample': 0, 'extra': {'final_conv_kernel': 1}, 'train_cfg': {}, 'test_cfg': {'flip_test': True, 'post_process': 'default', 'shift_heatmap': False, 'modulate_kernel': 11, 'use_udp': True}}}
[rank 3] dataset of task0 has been overided to {'type': 'COCOPosDatasetDev', 'kwargs': {'ann_file': 'openmmlab:s3://openmmlab/datasets/detection/coco/annotations/person_keypoints_train2017.json', 'img_prefix': 'openmmlab:s3://openmmlab/datasets/detection/coco/train2017/', 'use_udp': True, 'data_cfg': {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}}}
[rank 3] sampler of task0 has been overided to {'batch_size': 40, 'shuffle_strategy': 1}
[rank 0] >> task_info.decoder_share_group[[0]] ranks [0, 1, 2, 3]
[rank 0] neck of task0 has been overided to {'type': 'DoNothing', 'kwargs': {'backbone': 'None'}}
[rank 0] decoder of task0 has been overided to {'type': 'TopDownSimpleHead', 'kwargs': {'layer_norm': True, 'use_sync_bn': False, 'bn_sync_stats': False, 'in_channels': 768, 'out_channels': 17, 'num_deconv_layers': 2, 'num_deconv_filters': [256, 256], 'num_deconv_kernels': [4, 4], 'upsample': 0, 'extra': {'final_conv_kernel': 1}, 'train_cfg': {}, 'test_cfg': {'flip_test': True, 'post_process': 'default', 'shift_heatmap': False, 'modulate_kernel': 11, 'use_udp': True}}}
[rank 0] dataset of task0 has been overided to {'type': 'COCOPosDatasetDev', 'kwargs': {'ann_file': 'openmmlab:s3://openmmlab/datasets/detection/coco/annotations/person_keypoints_train2017.json', 'img_prefix': 'openmmlab:s3://openmmlab/datasets/detection/coco/train2017/', 'use_udp': True, 'data_cfg': {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}}}
[rank 0] sampler of task0 has been overided to {'batch_size': 40, 'shuffle_strategy': 1}
[rank 2] >> task_info.decoder_share_group[[0]] ranks [0, 1, 2, 3]
[rank 2] neck of task0 has been overided to {'type': 'DoNothing', 'kwargs': {'backbone': 'None'}}
[rank 2] decoder of task0 has been overided to {'type': 'TopDownSimpleHead', 'kwargs': {'layer_norm': True, 'use_sync_bn': False, 'bn_sync_stats': False, 'in_channels': 768, 'out_channels': 17, 'num_deconv_layers': 2, 'num_deconv_filters': [256, 256], 'num_deconv_kernels': [4, 4], 'upsample': 0, 'extra': {'final_conv_kernel': 1}, 'train_cfg': {}, 'test_cfg': {'flip_test': True, 'post_process': 'default', 'shift_heatmap': False, 'modulate_kernel': 11, 'use_udp': True}}}
[rank 1] >> task_info.decoder_share_group[[0]] ranks [0, 1, 2, 3]
[rank 2] dataset of task0 has been overided to {'type': 'COCOPosDatasetDev', 'kwargs': {'ann_file': 'openmmlab:s3://openmmlab/datasets/detection/coco/annotations/person_keypoints_train2017.json', 'img_prefix': 'openmmlab:s3://openmmlab/datasets/detection/coco/train2017/', 'use_udp': True, 'data_cfg': {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}}}
[rank 2] sampler of task0 has been overided to {'batch_size': 40, 'shuffle_strategy': 1}
[rank 1] neck of task0 has been overided to {'type': 'DoNothing', 'kwargs': {'backbone': 'None'}}
[rank 1] decoder of task0 has been overided to {'type': 'TopDownSimpleHead', 'kwargs': {'layer_norm': True, 'use_sync_bn': False, 'bn_sync_stats': False, 'in_channels': 768, 'out_channels': 17, 'num_deconv_layers': 2, 'num_deconv_filters': [256, 256], 'num_deconv_kernels': [4, 4], 'upsample': 0, 'extra': {'final_conv_kernel': 1}, 'train_cfg': {}, 'test_cfg': {'flip_test': True, 'post_process': 'default', 'shift_heatmap': False, 'modulate_kernel': 11, 'use_udp': True}}}
[rank 1] dataset of task0 has been overided to {'type': 'COCOPosDatasetDev', 'kwargs': {'ann_file': 'openmmlab:s3://openmmlab/datasets/detection/coco/annotations/person_keypoints_train2017.json', 'img_prefix': 'openmmlab:s3://openmmlab/datasets/detection/coco/train2017/', 'use_udp': True, 'data_cfg': {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}}}
[rank 1] sampler of task0 has been overided to {'batch_size': 40, 'shuffle_strategy': 1}
sync_print: rank 3, override tensor.cuda() to preserve task_specific flag
sync_print: rank 1, override tensor.cuda() to preserve task_specific flag
sync_print: rank 2, override tensor.cuda() to preserve task_specific flag
2022-09-26 10:06:17 4c7c0b1f SUCCESS: (pavi2.training) SummaryWriter is initialized, remember to close the SummaryWriter at the end of your program.

PAVI Info ###################################
Training：coco_pose_lr5e4x08_wd01_backbonebclip_layerdecay_stepLR_classichead_dpr3e1_wowin_LN_udp_50ep___SmallSetting___LSA_10p_small_setting4_add_DGMarket
Project：default
Training_id：114570
Training_url：http://autolink.parrots.sensetime.com/pages/content/project/3477/training/114570
Warning: If `Training_url` is not accessible, please upgrade your pavi version.
#############################################

[2022-09-26 10:06:17,790][           solver.py][line:  84][    INFO] auto_denan disabled!
sync_print: rank 0, override tensor.cuda() to preserve task_specific flag
[2022-09-26 10:06:17,794][     solver_deter.py][line:  59][    INFO] deterministic mode, seed: 42, worker_rank: True,                                   cudnn_deterministic: False
sync_print: rank 0, override tensor.half() to preserve task_specific flag
sync_print: rank 3, override tensor.half() to preserve task_specific flag
sync_print: rank 2, override tensor.half() to preserve task_specific flag
sync_print: rank 1, override tensor.half() to preserve task_specific flag
auto-resume from: /mnt/lustrenew/chencheng1/expr_files/vitruvian/devL2/L2_samll_setting_pose_FT/checkpoints/coco_pose_lr5e4x08_wd01_backbonebclip_layerdecay_stepLR_classichead_dpr3e1_wowin_LN_udp_50ep___SmallSetting___LSA_10p_small_setting4_add_DGMarket/ckpt_task_iter_newest.pth.tar
auto-resume from: /mnt/lustrenew/chencheng1/expr_files/vitruvian/devL2/L2_samll_setting_pose_FT/checkpoints/coco_pose_lr5e4x08_wd01_backbonebclip_layerdecay_stepLR_classichead_dpr3e1_wowin_LN_udp_50ep___SmallSetting___LSA_10p_small_setting4_add_DGMarket/ckpt_task_iter_newest.pth.tar
auto-resume from: /mnt/lustrenew/chencheng1/expr_files/vitruvian/devL2/L2_samll_setting_pose_FT/checkpoints/coco_pose_lr5e4x08_wd01_backbonebclip_layerdecay_stepLR_classichead_dpr3e1_wowin_LN_udp_50ep___SmallSetting___LSA_10p_small_setting4_add_DGMarket/ckpt_task_iter_newest.pth.tar
[rank 0] config[kwargs] {'ann_file': 'openmmlab:s3://openmmlab/datasets/detection/coco/annotations/person_keypoints_train2017.json', 'img_prefix': 'openmmlab:s3://openmmlab/datasets/detection/coco/train2017/', 'use_udp': True, 'data_cfg': {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}, 'ginfo': {'group': 1, 'task_size': 4, 'task_id': 0, 'task_rank': 0, 'task_root_rank': 0, 'root_group': 2, 'task_sizes': [4], 'task_root_ranks': [0], 'task_num': 1, 'backbone_share_group': 3, 'backbone_group_size': 1, 'backbone_task_size': 4, 'backbone_task_rank': 3, 'neck_share_group': 4, 'neck_group_size': 1, 'neck_task_size': 4, 'neck_task_rank': 3, 'decoder_share_group': 5, 'decoder_group_size': 1, 'decoder_task_size': 4, 'decoder_task_rank': 3, 'task_name': 'cocopose_256x192', 'task_names': ['cocopose_256x192'], 'task_weight': 1.0, 'task_type': 'normal', 'task_types': ['normal'], 'task_random_seed': 0}}
[rank 3] config[kwargs] {'ann_file': 'openmmlab:s3://openmmlab/datasets/detection/coco/annotations/person_keypoints_train2017.json', 'img_prefix': 'openmmlab:s3://openmmlab/datasets/detection/coco/train2017/', 'use_udp': True, 'data_cfg': {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}, 'ginfo': {'group': 1, 'task_size': 4, 'task_id': 0, 'task_rank': 3, 'task_root_rank': 0, 'root_group': 2, 'task_sizes': [4], 'task_root_ranks': [0], 'task_num': 1, 'backbone_share_group': 3, 'backbone_group_size': 1, 'backbone_task_size': 4, 'backbone_task_rank': 0, 'neck_share_group': 4, 'neck_group_size': 1, 'neck_task_size': 4, 'neck_task_rank': 0, 'decoder_share_group': 5, 'decoder_group_size': 1, 'decoder_task_size': 4, 'decoder_task_rank': 0, 'task_name': 'cocopose_256x192', 'task_names': ['cocopose_256x192'], 'task_weight': 1.0, 'task_type': 'normal', 'task_types': ['normal'], 'task_random_seed': 0}}
data_cfg0 {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}
[rank 2] config[kwargs] {'ann_file': 'openmmlab:s3://openmmlab/datasets/detection/coco/annotations/person_keypoints_train2017.json', 'img_prefix': 'openmmlab:s3://openmmlab/datasets/detection/coco/train2017/', 'use_udp': True, 'data_cfg': {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}, 'ginfo': {'group': 1, 'task_size': 4, 'task_id': 0, 'task_rank': 2, 'task_root_rank': 0, 'root_group': 2, 'task_sizes': [4], 'task_root_ranks': [0], 'task_num': 1, 'backbone_share_group': 3, 'backbone_group_size': 1, 'backbone_task_size': 4, 'backbone_task_rank': 1, 'neck_share_group': 4, 'neck_group_size': 1, 'neck_task_size': 4, 'neck_task_rank': 1, 'decoder_share_group': 5, 'decoder_group_size': 1, 'decoder_task_size': 4, 'decoder_task_rank': 1, 'task_name': 'cocopose_256x192', 'task_names': ['cocopose_256x192'], 'task_weight': 1.0, 'task_type': 'normal', 'task_types': ['normal'], 'task_random_seed': 0}}
data_cfg0 {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}
data_cfg0 {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
auto-resume from: /mnt/lustrenew/chencheng1/expr_files/vitruvian/devL2/L2_samll_setting_pose_FT/checkpoints/coco_pose_lr5e4x08_wd01_backbonebclip_layerdecay_stepLR_classichead_dpr3e1_wowin_LN_udp_50ep___SmallSetting___LSA_10p_small_setting4_add_DGMarket/ckpt_task_iter_newest.pth.tar
[rank 1] config[kwargs] {'ann_file': 'openmmlab:s3://openmmlab/datasets/detection/coco/annotations/person_keypoints_train2017.json', 'img_prefix': 'openmmlab:s3://openmmlab/datasets/detection/coco/train2017/', 'use_udp': True, 'data_cfg': {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}, 'ginfo': {'group': 1, 'task_size': 4, 'task_id': 0, 'task_rank': 1, 'task_root_rank': 0, 'root_group': 2, 'task_sizes': [4], 'task_root_ranks': [0], 'task_num': 1, 'backbone_share_group': 3, 'backbone_group_size': 1, 'backbone_task_size': 4, 'backbone_task_rank': 2, 'neck_share_group': 4, 'neck_group_size': 1, 'neck_task_size': 4, 'neck_task_rank': 2, 'decoder_share_group': 5, 'decoder_group_size': 1, 'decoder_task_size': 4, 'decoder_task_rank': 2, 'task_name': 'cocopose_256x192', 'task_names': ['cocopose_256x192'], 'task_weight': 1.0, 'task_type': 'normal', 'task_types': ['normal'], 'task_random_seed': 0}}
data_cfg0 {'image_size': [192, 256], 'heatmap_size': [48, 64], 'num_output_channels': 17, 'num_joints': 17, 'dataset_channel': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]], 'inference_channel': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'soft_nms': False, 'nms_thr': 1.0, 'oks_thr': 0.9, 'vis_thr': 0.2, 'use_gt_bbox': False, 'det_bbox_thr': 0.0, 'bbox_file': '/mnt/lustre/share/chencheng1/dataset/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'}
loading annotations into memory...
Done (t=9.67s)
creating index...
index created!
Done (t=10.84s)
creating index...
Done (t=11.04s)
creating index...
index created!
Done (t=11.29s)
creating index...
index created!
index created!
=> num_images: 118287
=> load 149813 samples
[rank 2] <core.data.datasets.images.pos_dataset_dev.COCOPosDatasetDev object at 0x7fda4d22e320>
=> num_images: 118287
=> load 149813 samples
[rank 1] <core.data.datasets.images.pos_dataset_dev.COCOPosDatasetDev object at 0x7f1baebad278>
=> num_images: 118287
=> load 149813 samples
[rank 3] <core.data.datasets.images.pos_dataset_dev.COCOPosDatasetDev object at 0x7fbf4708d390>
=> num_images: 118287
=> load 149813 samples
[rank 0] <core.data.datasets.images.pos_dataset_dev.COCOPosDatasetDev object at 0x7fd919bf1358>
Missing keys: ['blocks.2.attn.rel_pos_w', 'blocks.5.attn.rel_pos_h', 'blocks.8.attn.rel_pos_h', 'blocks.3.attn.rel_pos_w', 'blocks.2.attn.rel_pos_h', 'blocks.5.attn.rel_pos_w', 'blocks.9.attn.rel_pos_w', 'blocks.6.attn.rel_pos_w', 'blocks.3.attn.rel_pos_h', 'blocks.1.attn.rel_pos_w', 'blocks.4.attn.rel_pos_w', 'blocks.4.attn.rel_pos_h', 'blocks.10.attn.rel_pos_h', 'blocks.10.attn.rel_pos_w', 'blocks.11.attn.rel_pos_w', 'blocks.0.attn.rel_pos_w', 'blocks.9.attn.rel_pos_h', 'blocks.0.attn.rel_pos_h', 'blocks.11.attn.rel_pos_h', 'blocks.7.attn.rel_pos_w', 'blocks.1.attn.rel_pos_h', 'blocks.7.attn.rel_pos_h', 'blocks.8.attn.rel_pos_w', 'blocks.6.attn.rel_pos_h']
Missing keys: ['blocks.7.attn.rel_pos_h', 'blocks.5.attn.rel_pos_h', 'blocks.1.attn.rel_pos_w', 'blocks.2.attn.rel_pos_w', 'blocks.0.attn.rel_pos_h', 'blocks.11.attn.rel_pos_h', 'blocks.3.attn.rel_pos_h', 'blocks.9.attn.rel_pos_w', 'blocks.10.attn.rel_pos_h', 'blocks.3.attn.rel_pos_w', 'blocks.4.attn.rel_pos_w', 'blocks.9.attn.rel_pos_h', 'blocks.10.attn.rel_pos_w', 'blocks.11.attn.rel_pos_w', 'blocks.2.attn.rel_pos_h', 'blocks.4.attn.rel_pos_h', 'blocks.6.attn.rel_pos_h', 'blocks.1.attn.rel_pos_h', 'blocks.8.attn.rel_pos_h', 'blocks.5.attn.rel_pos_w', 'blocks.0.attn.rel_pos_w', 'blocks.6.attn.rel_pos_w', 'blocks.7.attn.rel_pos_w', 'blocks.8.attn.rel_pos_w']
Missing keys: ['blocks.10.attn.rel_pos_h', 'blocks.4.attn.rel_pos_w', 'blocks.6.attn.rel_pos_w', 'blocks.0.attn.rel_pos_w', 'blocks.6.attn.rel_pos_h', 'blocks.9.attn.rel_pos_h', 'blocks.3.attn.rel_pos_h', 'blocks.11.attn.rel_pos_w', 'blocks.5.attn.rel_pos_w', 'blocks.0.attn.rel_pos_h', 'blocks.8.attn.rel_pos_h', 'blocks.1.attn.rel_pos_w', 'blocks.10.attn.rel_pos_w', 'blocks.3.attn.rel_pos_w', 'blocks.8.attn.rel_pos_w', 'blocks.4.attn.rel_pos_h', 'blocks.11.attn.rel_pos_h', 'blocks.5.attn.rel_pos_h', 'blocks.7.attn.rel_pos_w', 'blocks.2.attn.rel_pos_w', 'blocks.2.attn.rel_pos_h', 'blocks.9.attn.rel_pos_w', 'blocks.1.attn.rel_pos_h', 'blocks.7.attn.rel_pos_h']
Missing keys: ['blocks.1.attn.rel_pos_w', 'blocks.8.attn.rel_pos_w', 'blocks.6.attn.rel_pos_h', 'blocks.5.attn.rel_pos_w', 'blocks.0.attn.rel_pos_h', 'blocks.3.attn.rel_pos_w', 'blocks.10.attn.rel_pos_h', 'blocks.11.attn.rel_pos_w', 'blocks.2.attn.rel_pos_w', 'blocks.8.attn.rel_pos_h', 'blocks.4.attn.rel_pos_h', 'blocks.11.attn.rel_pos_h', 'blocks.9.attn.rel_pos_h', 'blocks.10.attn.rel_pos_w', 'blocks.0.attn.rel_pos_w', 'blocks.9.attn.rel_pos_w', 'blocks.3.attn.rel_pos_h', 'blocks.7.attn.rel_pos_w', 'blocks.6.attn.rel_pos_w', 'blocks.7.attn.rel_pos_h', 'blocks.5.attn.rel_pos_h', 'blocks.4.attn.rel_pos_w', 'blocks.2.attn.rel_pos_h', 'blocks.1.attn.rel_pos_h']
finish load
finish load
finish load

finish load
sync_print: rank 1, Number of conv/bn params: 0.59M
sync_print: rank 1, Number of linear params: 85.02M
sync_print: rank 3, Number of conv/bn params: 0.59M
sync_print: rank 3, Number of linear params: 85.02M
sync_print: rank 2, Number of conv/bn params: 0.59M
sync_print: rank 2, Number of linear params: 85.02M
sync_print: rank 0, Number of conv/bn params: 0.59M
sync_print: rank 0, Number of linear params: 85.02M
[rank 1] add param pos_embed as backbone_specific
[rank 1] add param patch_embed.proj.weight as backbone_specific
[rank 1] add param patch_embed.proj.bias as backbone_specific
[rank 1] add param blocks.0.norm1.weight as backbone_specific
[rank 1] add param blocks.0.norm1.bias as backbone_specific
[rank 1] add param blocks.0.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.0.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.0.attn.qkv.weight as backbone_specific
[rank 1] add param blocks.0.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.0.attn.proj.weight as backbone_specific
[rank 1] add param blocks.0.attn.proj.bias as backbone_specific
[rank 1] add param blocks.0.norm2.weight as backbone_specific
[rank 1] add param blocks.0.norm2.bias as backbone_specific
[rank 1] add param blocks.0.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.0.mlp.fc1.bias as backbone_specific
[rank 1] add param blocks.0.mlp.fc2.weight as backbone_specific
[rank 1] add param blocks.0.mlp.fc2.bias as backbone_specific
[rank 1] add param blocks.1.norm1.weight as backbone_specific
[rank 1] add param blocks.1.norm1.bias as backbone_specific
[rank 1] add param blocks.1.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.1.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.1.attn.qkv.weight as backbone_specific
[rank 1] add param blocks.1.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.1.attn.proj.weight as backbone_specific
[rank 1] add param blocks.1.attn.proj.bias as backbone_specific
[rank 1] add param blocks.1.norm2.weight as backbone_specific
[rank 1] add param blocks.1.norm2.bias as backbone_specific
[rank 1] add param blocks.1.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.1.mlp.fc1.bias as backbone_specific
[rank 1] add param blocks.1.mlp.fc2.weight as backbone_specific
[rank 1] add param blocks.1.mlp.fc2.bias as backbone_specific
[rank 1] add param blocks.2.norm1.weight as backbone_specific
[rank 1] add param blocks.2.norm1.bias as backbone_specific
[rank 1] add param blocks.2.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.2.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.2.attn.qkv.weight as backbone_specific
[rank 1] add param blocks.2.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.2.attn.proj.weight as backbone_specific
[rank 1] add param blocks.2.attn.proj.bias as backbone_specific
[rank 1] add param blocks.2.norm2.weight as backbone_specific
[rank 1] add param blocks.2.norm2.bias as backbone_specific
[rank 1] add param blocks.2.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.2.mlp.fc1.bias as backbone_specific
[rank 1] add param blocks.2.mlp.fc2.weight as backbone_specific
[rank 1] add param blocks.2.mlp.fc2.bias as backbone_specific
[rank 1] add param blocks.3.norm1.weight as backbone_specific
[rank 1] add param blocks.3.norm1.bias as backbone_specific
[rank 1] add param blocks.3.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.3.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.3.attn.qkv.weight as backbone_specific
[rank 1] add param blocks.3.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.3.attn.proj.weight as backbone_specific
[rank 1] add param blocks.3.attn.proj.bias as backbone_specific
[rank 1] add param blocks.3.norm2.weight as backbone_specific
[rank 1] add param blocks.3.norm2.bias as backbone_specific
[rank 1] add param blocks.3.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.3.mlp.fc1.bias as backbone_specific
[rank 1] add param blocks.3.mlp.fc2.weight as backbone_specific
[rank 1] add param blocks.3.mlp.fc2.bias as backbone_specific
[rank 1] add param blocks.4.norm1.weight as backbone_specific
[rank 1] add param blocks.4.norm1.bias as backbone_specific
[rank 1] add param blocks.4.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.4.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.4.attn.qkv.weight as backbone_specific
[rank 1] add param blocks.4.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.4.attn.proj.weight as backbone_specific
[rank 1] add param blocks.4.attn.proj.bias as backbone_specific
[rank 1] add param blocks.4.norm2.weight as backbone_specific
[rank 1] add param blocks.4.norm2.bias as backbone_specific
[rank 1] add param blocks.4.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.4.mlp.fc1.bias as backbone_specific
[rank 3] add param pos_embed as backbone_specific
[rank 1] add param blocks.4.mlp.fc2.weight as backbone_specific
[rank 1] add param blocks.4.mlp.fc2.bias as backbone_specific
[rank 3] add param patch_embed.proj.weight as backbone_specific
[rank 1] add param blocks.5.norm1.weight as backbone_specific
[rank 3] add param patch_embed.proj.bias as backbone_specific
[rank 1] add param blocks.5.norm1.bias as backbone_specific
[rank 1] add param blocks.5.attn.rel_pos_h as backbone_specific
[rank 2] add param pos_embed as backbone_specific
[rank 1] add param blocks.5.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.5.attn.qkv.weight as backbone_specific
[rank 2] add param patch_embed.proj.weight as backbone_specific
[rank 2] add param patch_embed.proj.bias as backbone_specific
[rank 3] add param blocks.0.norm1.weight as backbone_specific
[rank 3] add param blocks.0.norm1.bias as backbone_specific
[rank 3] add param blocks.0.attn.rel_pos_h as backbone_specific
[rank 3] add param blocks.0.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.5.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.5.attn.proj.weight as backbone_specific
[rank 1] add param blocks.5.attn.proj.bias as backbone_specific
[rank 2] add param blocks.0.norm1.weight as backbone_specific
[rank 2] add param blocks.0.norm1.bias as backbone_specific
[rank 3] add param blocks.0.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.0.attn.qkv.bias as backbone_specific
[rank 3] add param blocks.0.attn.proj.weight as backbone_specific
[rank 1] add param blocks.5.norm2.weight as backbone_specific
[rank 1] add param blocks.5.norm2.bias as backbone_specific
[rank 2] add param blocks.0.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.0.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.0.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.0.attn.proj.bias as backbone_specific
[rank 3] add param blocks.0.norm2.weight as backbone_specific
[rank 1] add param blocks.5.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.5.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.0.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.0.attn.proj.weight as backbone_specific
[rank 3] add param blocks.0.norm2.bias as backbone_specific
[rank 3] add param blocks.0.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.5.mlp.fc2.weight as backbone_specific
[rank 1] add param blocks.5.mlp.fc2.bias as backbone_specific
[rank 2] add param blocks.0.attn.proj.bias as backbone_specific
[rank 2] add param blocks.0.norm2.weight as backbone_specific
[rank 3] add param blocks.0.mlp.fc1.bias as backbone_specific
[rank 3] add param blocks.0.mlp.fc2.weight as backbone_specific
[rank 1] add param blocks.6.norm1.weight as backbone_specific
[rank 1] add param blocks.6.norm1.bias as backbone_specific
[rank 1] add param blocks.6.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.0.norm2.bias as backbone_specific
[rank 2] add param blocks.0.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.0.mlp.fc2.bias as backbone_specific
[rank 3] add param blocks.1.norm1.weight as backbone_specific
[rank 1] add param blocks.6.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.6.attn.qkv.weight as backbone_specific
[rank 1] add param blocks.6.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.0.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.0.mlp.fc2.weight as backbone_specific
[rank 2] add param blocks.0.mlp.fc2.bias as backbone_specific
[rank 3] add param blocks.1.norm1.bias as backbone_specific
[rank 3] add param blocks.1.attn.rel_pos_h as backbone_specific
[rank 3] add param blocks.1.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.6.attn.proj.weight as backbone_specific
[rank 1] add param blocks.6.attn.proj.bias as backbone_specific
[rank 2] add param blocks.1.norm1.weight as backbone_specific
[rank 2] add param blocks.1.norm1.bias as backbone_specific
[rank 3] add param blocks.1.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.1.attn.qkv.bias as backbone_specific
[rank 3] add param blocks.1.attn.proj.weight as backbone_specific
[rank 1] add param blocks.6.norm2.weight as backbone_specific
[rank 1] add param blocks.6.norm2.bias as backbone_specific
[rank 1] add param blocks.6.mlp.fc1.weight as backbone_specific
[rank 2] add param blocks.1.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.1.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.1.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.1.attn.proj.bias as backbone_specific
[rank 3] add param blocks.1.norm2.weight as backbone_specific
[rank 1] add param blocks.6.mlp.fc1.bias as backbone_specific
[rank 1] add param blocks.6.mlp.fc2.weight as backbone_specific
[rank 1] add param blocks.6.mlp.fc2.bias as backbone_specific
[rank 2] add param blocks.1.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.1.attn.proj.weight as backbone_specific
[rank 2] add param blocks.1.attn.proj.bias as backbone_specific
[rank 3] add param blocks.1.norm2.bias as backbone_specific
[rank 3] add param blocks.1.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.1.mlp.fc1.bias as backbone_specific
[rank 1] add param blocks.7.norm1.weight as backbone_specific
[rank 1] add param blocks.7.norm1.bias as backbone_specific
[rank 2] add param blocks.1.norm2.weight as backbone_specific
[rank 2] add param blocks.1.norm2.bias as backbone_specific
[rank 1] add param blocks.7.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.7.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.7.attn.qkv.weight as backbone_specific
[rank 2] add param blocks.1.mlp.fc1.weight as backbone_specific
[rank 2] add param blocks.1.mlp.fc1.bias as backbone_specific
[rank 3] add param blocks.1.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.1.mlp.fc2.bias as backbone_specific
[rank 3] add param blocks.2.norm1.weight as backbone_specific
[rank 3] add param blocks.2.norm1.bias as backbone_specific
[rank 1] add param blocks.7.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.7.attn.proj.weight as backbone_specific
[rank 1] add param blocks.7.attn.proj.bias as backbone_specific
[rank 2] add param blocks.1.mlp.fc2.weight as backbone_specific
[rank 2] add param blocks.1.mlp.fc2.bias as backbone_specific
[rank 3] add param blocks.2.attn.rel_pos_h as backbone_specific
[rank 3] add param blocks.2.attn.rel_pos_w as backbone_specific
[rank 3] add param blocks.2.attn.qkv.weight as backbone_specific
[rank 1] add param blocks.7.norm2.weight as backbone_specific
[rank 1] add param blocks.7.norm2.bias as backbone_specific
[rank 2] add param blocks.2.norm1.weight as backbone_specific
[rank 2] add param blocks.2.norm1.bias as backbone_specific
[rank 2] add param blocks.2.attn.rel_pos_h as backbone_specific
[rank 3] add param blocks.2.attn.qkv.bias as backbone_specific
[rank 3] add param blocks.2.attn.proj.weight as backbone_specific
[rank 3] add param blocks.2.attn.proj.bias as backbone_specific
[rank 1] add param blocks.7.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.7.mlp.fc1.bias as backbone_specific
[rank 1] add param blocks.7.mlp.fc2.weight as backbone_specific
[rank 2] add param blocks.2.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.2.attn.qkv.weight as backbone_specific
[rank 2] add param blocks.2.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.7.mlp.fc2.bias as backbone_specific
[rank 1] add param blocks.8.norm1.weight as backbone_specific
[rank 1] add param blocks.8.norm1.bias as backbone_specific
[rank 1] add param blocks.8.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.8.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.2.attn.proj.weight as backbone_specific
[rank 2] add param blocks.2.attn.proj.bias as backbone_specific
[rank 2] add param blocks.2.norm2.weight as backbone_specific
[rank 2] add param blocks.2.norm2.bias as backbone_specific
[rank 3] add param blocks.2.norm2.weight as backbone_specific
[rank 3] add param blocks.2.norm2.bias as backbone_specific
[rank 3] add param blocks.2.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.2.mlp.fc1.bias as backbone_specific
[rank 3] add param blocks.2.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.2.mlp.fc2.bias as backbone_specific
[rank 1] add param blocks.8.attn.qkv.weight as backbone_specific
[rank 1] add param blocks.8.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.8.attn.proj.weight as backbone_specific
[rank 2] add param blocks.2.mlp.fc1.weight as backbone_specific
[rank 2] add param blocks.2.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.2.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.3.norm1.weight as backbone_specific
[rank 3] add param blocks.3.norm1.bias as backbone_specific
[rank 3] add param blocks.3.attn.rel_pos_h as backbone_specific
[rank 3] add param blocks.3.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.8.attn.proj.bias as backbone_specific
[rank 1] add param blocks.8.norm2.weight as backbone_specific
[rank 1] add param blocks.8.norm2.bias as backbone_specific
[rank 2] add param blocks.2.mlp.fc2.bias as backbone_specific
[rank 2] add param blocks.3.norm1.weight as backbone_specific
[rank 2] add param blocks.3.norm1.bias as backbone_specific
[rank 3] add param blocks.3.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.3.attn.qkv.bias as backbone_specific
[rank 3] add param blocks.3.attn.proj.weight as backbone_specific
[rank 1] add param blocks.8.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.8.mlp.fc1.bias as backbone_specific
[rank 1] add param blocks.8.mlp.fc2.weight as backbone_specific
[rank 2] add param blocks.3.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.3.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.3.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.3.attn.proj.bias as backbone_specific
[rank 3] add param blocks.3.norm2.weight as backbone_specific
[rank 1] add param blocks.8.mlp.fc2.bias as backbone_specific
[rank 1] add param blocks.9.norm1.weight as backbone_specific
[rank 1] add param blocks.9.norm1.bias as backbone_specific
[rank 2] add param blocks.3.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.3.attn.proj.weight as backbone_specific
[rank 2] add param blocks.3.attn.proj.bias as backbone_specific
[rank 3] add param blocks.3.norm2.bias as backbone_specific
[rank 3] add param blocks.3.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.3.mlp.fc1.bias as backbone_specific
[rank 1] add param blocks.9.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.9.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.9.attn.qkv.weight as backbone_specific
[rank 2] add param blocks.3.norm2.weight as backbone_specific
[rank 2] add param blocks.3.norm2.bias as backbone_specific
[rank 3] add param blocks.3.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.3.mlp.fc2.bias as backbone_specific
[rank 1] add param blocks.9.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.9.attn.proj.weight as backbone_specific
[rank 1] add param blocks.9.attn.proj.bias as backbone_specific
[rank 2] add param blocks.3.mlp.fc1.weight as backbone_specific
[rank 2] add param blocks.3.mlp.fc1.bias as backbone_specific
[rank 3] add param blocks.4.norm1.weight as backbone_specific
[rank 3] add param blocks.4.norm1.bias as backbone_specific
[rank 3] add param blocks.4.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.9.norm2.weight as backbone_specific
[rank 1] add param blocks.9.norm2.bias as backbone_specific
[rank 2] add param blocks.3.mlp.fc2.weight as backbone_specific
[rank 2] add param blocks.3.mlp.fc2.bias as backbone_specific
[rank 2] add param blocks.4.norm1.weight as backbone_specific
[rank 3] add param blocks.4.attn.rel_pos_w as backbone_specific
[rank 3] add param blocks.4.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.4.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.9.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.9.mlp.fc1.bias as backbone_specific
[rank 1] add param blocks.9.mlp.fc2.weight as backbone_specific
[rank 2] add param blocks.4.norm1.bias as backbone_specific
[rank 2] add param blocks.4.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.4.attn.rel_pos_w as backbone_specific
[rank 3] add param blocks.4.attn.proj.weight as backbone_specific
[rank 3] add param blocks.4.attn.proj.bias as backbone_specific
[rank 1] add param blocks.9.mlp.fc2.bias as backbone_specific
[rank 1] add param blocks.10.norm1.weight as backbone_specific
[rank 2] add param blocks.4.attn.qkv.weight as backbone_specific
[rank 2] add param blocks.4.attn.qkv.bias as backbone_specific
[rank 3] add param blocks.4.norm2.weight as backbone_specific
[rank 3] add param blocks.4.norm2.bias as backbone_specific
[rank 1] add param blocks.10.norm1.bias as backbone_specific
[rank 1] add param blocks.10.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.10.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.4.attn.proj.weight as backbone_specific
[rank 2] add param blocks.4.attn.proj.bias as backbone_specific
[rank 3] add param blocks.4.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.4.mlp.fc1.bias as backbone_specific
[rank 3] add param blocks.4.mlp.fc2.weight as backbone_specific
[rank 1] add param blocks.10.attn.qkv.weight as backbone_specific
[rank 1] add param blocks.10.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.10.attn.proj.weight as backbone_specific
[rank 2] add param blocks.4.norm2.weight as backbone_specific
[rank 2] add param blocks.4.norm2.bias as backbone_specific
[rank 2] add param blocks.4.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.4.mlp.fc2.bias as backbone_specific
[rank 3] add param blocks.5.norm1.weight as backbone_specific
[rank 1] add param blocks.10.attn.proj.bias as backbone_specific
[rank 1] add param blocks.10.norm2.weight as backbone_specific
[rank 2] add param blocks.4.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.4.mlp.fc2.weight as backbone_specific
[rank 2] add param blocks.4.mlp.fc2.bias as backbone_specific
[rank 3] add param blocks.5.norm1.bias as backbone_specific
[rank 3] add param blocks.5.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.10.norm2.bias as backbone_specific
[rank 1] add param blocks.10.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.10.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.5.norm1.weight as backbone_specific
[rank 2] add param blocks.5.norm1.bias as backbone_specific
[rank 3] add param blocks.5.attn.rel_pos_w as backbone_specific
[rank 3] add param blocks.5.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.5.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.10.mlp.fc2.weight as backbone_specific
[rank 1] add param blocks.10.mlp.fc2.bias as backbone_specific
[rank 2] add param blocks.5.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.5.attn.rel_pos_w as backbone_specific
[rank 3] add param blocks.5.attn.proj.weight as backbone_specific
[rank 3] add param blocks.5.attn.proj.bias as backbone_specific
[rank 1] add param blocks.11.norm1.weight as backbone_specific
[rank 1] add param blocks.11.norm1.bias as backbone_specific
[rank 2] add param blocks.5.attn.qkv.weight as backbone_specific
[rank 2] add param blocks.5.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.5.attn.proj.weight as backbone_specific
[rank 3] add param blocks.5.norm2.weight as backbone_specific
[rank 3] add param blocks.5.norm2.bias as backbone_specific
[rank 1] add param blocks.11.attn.rel_pos_h as backbone_specific
[rank 1] add param blocks.11.attn.rel_pos_w as backbone_specific
[rank 1] add param blocks.11.attn.qkv.weight as backbone_specific
[rank 2] add param blocks.5.attn.proj.bias as backbone_specific
[rank 2] add param blocks.5.norm2.weight as backbone_specific
[rank 3] add param blocks.5.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.5.mlp.fc1.bias as backbone_specific
[rank 1] add param blocks.11.attn.qkv.bias as backbone_specific
[rank 1] add param blocks.11.attn.proj.weight as backbone_specific
[rank 1] add param blocks.11.attn.proj.bias as backbone_specific
[rank 2] add param blocks.5.norm2.bias as backbone_specific
[rank 2] add param blocks.5.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.5.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.5.mlp.fc2.bias as backbone_specific
[rank 1] add param blocks.11.norm2.weight as backbone_specific
[rank 1] add param blocks.11.norm2.bias as backbone_specific
[rank 2] add param blocks.5.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.5.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.6.norm1.weight as backbone_specific
[rank 3] add param blocks.6.norm1.bias as backbone_specific
[rank 1] add param blocks.11.mlp.fc1.weight as backbone_specific
[rank 1] add param blocks.11.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.5.mlp.fc2.bias as backbone_specific
[rank 2] add param blocks.6.norm1.weight as backbone_specific
[rank 3] add param blocks.6.attn.rel_pos_h as backbone_specific
[rank 3] add param blocks.6.attn.rel_pos_w as backbone_specific
[rank 3] add param blocks.6.attn.qkv.weight as backbone_specific
[rank 1] add param blocks.11.mlp.fc2.weight as backbone_specific
[rank 1] add param blocks.11.mlp.fc2.bias as backbone_specific
[rank 2] add param blocks.6.norm1.bias as backbone_specific
[rank 2] add param blocks.6.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.6.attn.rel_pos_w as backbone_specific
[rank 3] add param blocks.6.attn.qkv.bias as backbone_specific
[rank 3] add param blocks.6.attn.proj.weight as backbone_specific
[rank 3] add param blocks.6.attn.proj.bias as backbone_specific
[rank 1] add param norm.weight as backbone_specific
[rank 1] add param norm.bias as backbone_specific
[rank 2] add param blocks.6.attn.qkv.weight as backbone_specific
[rank 2] add param blocks.6.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.6.attn.proj.weight as backbone_specific
[rank 2] add param blocks.6.attn.proj.bias as backbone_specific
[rank 3] add param blocks.6.norm2.weight as backbone_specific
[rank 3] add param blocks.6.norm2.bias as backbone_specific
[rank 3] add param blocks.6.mlp.fc1.weight as backbone_specific
[rank 2] add param blocks.6.norm2.weight as backbone_specific
[rank 3] add param blocks.6.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.6.norm2.bias as backbone_specific
[rank 3] add param blocks.6.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.6.mlp.fc2.bias as backbone_specific
[rank 2] add param blocks.6.mlp.fc1.weight as backbone_specific
[rank 2] add param blocks.6.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.6.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.7.norm1.weight as backbone_specific
[rank 3] add param blocks.7.norm1.bias as backbone_specific
[rank 2] add param blocks.6.mlp.fc2.bias as backbone_specific
[rank 3] add param blocks.7.attn.rel_pos_h as backbone_specific
[rank 3] add param blocks.7.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.7.norm1.weight as backbone_specific
[rank 2] add param blocks.7.norm1.bias as backbone_specific
[rank 3] add param blocks.7.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.7.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.7.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.7.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.7.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.7.attn.proj.weight as backbone_specific
[rank 3] add param blocks.7.attn.proj.bias as backbone_specific
[rank 2] add param blocks.7.attn.qkv.bias as backbone_specific
[rank 3] add param blocks.7.norm2.weight as backbone_specific
[rank 3] add param blocks.7.norm2.bias as backbone_specific
[rank 2] add param blocks.7.attn.proj.weight as backbone_specific
[rank 2] add param blocks.7.attn.proj.bias as backbone_specific
[rank 3] add param blocks.7.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.7.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.7.norm2.weight as backbone_specific
[rank 2] add param blocks.7.norm2.bias as backbone_specific
[rank 2] add param blocks.7.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.7.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.7.mlp.fc2.bias as backbone_specific
[rank 2] add param blocks.7.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.7.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.8.norm1.weight as backbone_specific
[rank 3] add param blocks.8.norm1.bias as backbone_specific
[rank 2] add param blocks.7.mlp.fc2.bias as backbone_specific
[rank 3] add param blocks.8.attn.rel_pos_h as backbone_specific
[rank 3] add param blocks.8.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.8.norm1.weight as backbone_specific
[rank 2] add param blocks.8.norm1.bias as backbone_specific
[rank 3] add param blocks.8.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.8.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.8.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.8.attn.rel_pos_w as backbone_specific
[rank 3] add param blocks.8.attn.proj.weight as backbone_specific
[rank 3] add param blocks.8.attn.proj.bias as backbone_specific
[rank 2] add param blocks.8.attn.qkv.weight as backbone_specific
[rank 2] add param blocks.8.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.8.attn.proj.weight as backbone_specific
[rank 3] add param blocks.8.norm2.weight as backbone_specific
[rank 3] add param blocks.8.norm2.bias as backbone_specific
[rank 2] add param blocks.8.attn.proj.bias as backbone_specific
[rank 3] add param blocks.8.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.8.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.8.norm2.weight as backbone_specific
[rank 2] add param blocks.8.norm2.bias as backbone_specific
[rank 2] add param blocks.8.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.8.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.8.mlp.fc2.bias as backbone_specific
[rank 2] add param blocks.8.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.8.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.9.norm1.weight as backbone_specific
[rank 3] add param blocks.9.norm1.bias as backbone_specific
[rank 2] add param blocks.8.mlp.fc2.bias as backbone_specific
[rank 3] add param blocks.9.attn.rel_pos_h as backbone_specific
[rank 3] add param blocks.9.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.9.norm1.weight as backbone_specific
[rank 2] add param blocks.9.norm1.bias as backbone_specific
[rank 2] add param blocks.9.attn.rel_pos_h as backbone_specific
[rank 3] add param blocks.9.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.9.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.9.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.9.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.9.attn.proj.weight as backbone_specific
[rank 3] add param blocks.9.attn.proj.bias as backbone_specific
[rank 1] add param deconv_layers.0.weight as decoder_specific
[rank 2] add param blocks.9.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.9.attn.proj.weight as backbone_specific
[rank 3] add param blocks.9.norm2.weight as backbone_specific
[rank 3] add param blocks.9.norm2.bias as backbone_specific
[rank 1] add param deconv_layers.1.weight as decoder_specific
[rank 1] add param deconv_layers.1.bias as decoder_specific
[rank 2] add param blocks.9.attn.proj.bias as backbone_specific
[rank 2] add param blocks.9.norm2.weight as backbone_specific
[rank 3] add param blocks.9.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.9.mlp.fc1.bias as backbone_specific
[rank 1] add param deconv_layers.3.weight as decoder_specific
[rank 1] add param deconv_layers.4.weight as decoder_specific
[rank 2] add param blocks.9.norm2.bias as backbone_specific
[rank 2] add param blocks.9.mlp.fc1.weight as backbone_specific
[rank 2] add param blocks.9.mlp.fc1.bias as backbone_specific
[rank 3] add param blocks.9.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.9.mlp.fc2.bias as backbone_specific
[rank 1] add param deconv_layers.4.bias as decoder_specific
[rank 1] add param final_layer.weight as decoder_specific
[rank 1] add param final_layer.bias as decoder_specific
[rank 2] add param blocks.9.mlp.fc2.weight as backbone_specific
[rank 2] add param blocks.9.mlp.fc2.bias as backbone_specific
[rank 3] add param blocks.10.norm1.weight as backbone_specific
[rank 3] add param blocks.10.norm1.bias as backbone_specific
[rank 3] add param blocks.10.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.10.norm1.weight as backbone_specific
[rank 2] add param blocks.10.norm1.bias as backbone_specific
[rank 3] add param blocks.10.attn.rel_pos_w as backbone_specific
[rank 3] add param blocks.10.attn.qkv.weight as backbone_specific
[rank 2] add param blocks.10.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.10.attn.rel_pos_w as backbone_specific
[rank 3] add param blocks.10.attn.qkv.bias as backbone_specific
[rank 3] add param blocks.10.attn.proj.weight as backbone_specific
[rank 2] add param blocks.10.attn.qkv.weight as backbone_specific
[rank 2] add param blocks.10.attn.qkv.bias as backbone_specific
[rank 3] add param blocks.10.attn.proj.bias as backbone_specific
[rank 2] add param blocks.10.attn.proj.weight as backbone_specific
[rank 3] add param blocks.10.norm2.weight as backbone_specific
[rank 3] add param blocks.10.norm2.bias as backbone_specific
[rank 2] add param blocks.10.attn.proj.bias as backbone_specific
[rank 2] add param blocks.10.norm2.weight as backbone_specific
[rank 2] add param blocks.10.norm2.bias as backbone_specific
[rank 3] add param blocks.10.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.10.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.10.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.10.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.10.mlp.fc2.bias as backbone_specific
[rank 2] add param blocks.10.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.10.mlp.fc2.weight as backbone_specific
[rank 2] add param blocks.10.mlp.fc2.bias as backbone_specific
[rank 3] add param blocks.11.norm1.weight as backbone_specific
[rank 3] add param blocks.11.norm1.bias as backbone_specific
[rank 2] add param blocks.11.norm1.weight as backbone_specific
[rank 2] add param blocks.11.norm1.bias as backbone_specific
[rank 3] add param blocks.11.attn.rel_pos_h as backbone_specific
[rank 3] add param blocks.11.attn.rel_pos_w as backbone_specific
[rank 3] add param blocks.11.attn.qkv.weight as backbone_specific
[rank 3] add param blocks.11.attn.qkv.bias as backbone_specific
[rank 2] add param blocks.11.attn.rel_pos_h as backbone_specific
[rank 2] add param blocks.11.attn.rel_pos_w as backbone_specific
[rank 2] add param blocks.11.attn.qkv.weight as backbone_specific
[rank 2] add param blocks.11.attn.qkv.bias as backbone_specific
[rank 3] add param blocks.11.attn.proj.weight as backbone_specific
[rank 3] add param blocks.11.attn.proj.bias as backbone_specific
[rank 2] add param blocks.11.attn.proj.weight as backbone_specific
[rank 2] add param blocks.11.attn.proj.bias as backbone_specific
[rank 3] add param blocks.11.norm2.weight as backbone_specific
[rank 3] add param blocks.11.norm2.bias as backbone_specific
[rank 2] add param blocks.11.norm2.weight as backbone_specific
[rank 2] add param blocks.11.norm2.bias as backbone_specific
[rank 2] add param blocks.11.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.11.mlp.fc1.weight as backbone_specific
[rank 3] add param blocks.11.mlp.fc1.bias as backbone_specific
[rank 3] add param blocks.11.mlp.fc2.weight as backbone_specific
[rank 2] add param blocks.11.mlp.fc1.bias as backbone_specific
[rank 2] add param blocks.11.mlp.fc2.weight as backbone_specific
[rank 3] add param blocks.11.mlp.fc2.bias as backbone_specific
[rank 3] add param norm.weight as backbone_specific
[rank 2] add param blocks.11.mlp.fc2.bias as backbone_specific
[rank 3] add param norm.bias as backbone_specific
[rank 2] add param norm.weight as backbone_specific
[rank 2] add param norm.bias as backbone_specific
[rank 3] add param deconv_layers.0.weight as decoder_specific
[rank 3] add param deconv_layers.1.weight as decoder_specific
[rank 2] add param deconv_layers.0.weight as decoder_specific
[rank 3] add param deconv_layers.1.bias as decoder_specific
[rank 3] add param deconv_layers.3.weight as decoder_specific
[rank 2] add param deconv_layers.1.weight as decoder_specific
[rank 2] add param deconv_layers.1.bias as decoder_specific
[rank 2] add param deconv_layers.3.weight as decoder_specific
[rank 3] add param deconv_layers.4.weight as decoder_specific
[rank 3] add param deconv_layers.4.bias as decoder_specific
[rank 3] add param final_layer.weight as decoder_specific
[rank 2] add param deconv_layers.4.weight as decoder_specific
[rank 2] add param deconv_layers.4.bias as decoder_specific
[rank 3] add param final_layer.bias as decoder_specific
[rank 2] add param final_layer.weight as decoder_specific
[rank 2] add param final_layer.bias as decoder_specific
[rank 0] add param pos_embed as backbone_specific
[rank 0] add param patch_embed.proj.weight as backbone_specific
[rank 0] add param patch_embed.proj.bias as backbone_specific
[rank 0] add param blocks.0.norm1.weight as backbone_specific
[rank 0] add param blocks.0.norm1.bias as backbone_specific
[rank 0] add param blocks.0.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.0.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.0.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.0.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.0.attn.proj.weight as backbone_specific
[rank 0] add param blocks.0.attn.proj.bias as backbone_specific
[rank 0] add param blocks.0.norm2.weight as backbone_specific
[rank 0] add param blocks.0.norm2.bias as backbone_specific
[rank 0] add param blocks.0.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.0.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.0.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.0.mlp.fc2.bias as backbone_specific
[rank 0] add param blocks.1.norm1.weight as backbone_specific
[rank 0] add param blocks.1.norm1.bias as backbone_specific
[rank 0] add param blocks.1.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.1.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.1.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.1.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.1.attn.proj.weight as backbone_specific
[rank 0] add param blocks.1.attn.proj.bias as backbone_specific
[rank 0] add param blocks.1.norm2.weight as backbone_specific
[rank 0] add param blocks.1.norm2.bias as backbone_specific
[rank 0] add param blocks.1.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.1.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.1.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.1.mlp.fc2.bias as backbone_specific
[rank 0] add param blocks.2.norm1.weight as backbone_specific
[rank 0] add param blocks.2.norm1.bias as backbone_specific
[rank 0] add param blocks.2.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.2.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.2.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.2.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.2.attn.proj.weight as backbone_specific
[rank 0] add param blocks.2.attn.proj.bias as backbone_specific
[rank 0] add param blocks.2.norm2.weight as backbone_specific
[rank 0] add param blocks.2.norm2.bias as backbone_specific
[rank 0] add param blocks.2.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.2.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.2.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.2.mlp.fc2.bias as backbone_specific
[rank 0] add param blocks.3.norm1.weight as backbone_specific
[rank 0] add param blocks.3.norm1.bias as backbone_specific
[rank 0] add param blocks.3.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.3.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.3.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.3.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.3.attn.proj.weight as backbone_specific
[rank 0] add param blocks.3.attn.proj.bias as backbone_specific
[rank 0] add param blocks.3.norm2.weight as backbone_specific
[rank 0] add param blocks.3.norm2.bias as backbone_specific
[rank 0] add param blocks.3.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.3.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.3.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.3.mlp.fc2.bias as backbone_specific
[rank 0] add param blocks.4.norm1.weight as backbone_specific
[rank 0] add param blocks.4.norm1.bias as backbone_specific
[rank 0] add param blocks.4.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.4.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.4.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.4.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.4.attn.proj.weight as backbone_specific
[rank 0] add param blocks.4.attn.proj.bias as backbone_specific
[rank 0] add param blocks.4.norm2.weight as backbone_specific
[rank 0] add param blocks.4.norm2.bias as backbone_specific
[rank 0] add param blocks.4.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.4.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.4.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.4.mlp.fc2.bias as backbone_specific
[rank 0] add param blocks.5.norm1.weight as backbone_specific
[rank 0] add param blocks.5.norm1.bias as backbone_specific
[rank 0] add param blocks.5.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.5.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.5.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.5.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.5.attn.proj.weight as backbone_specific
[rank 0] add param blocks.5.attn.proj.bias as backbone_specific
[rank 0] add param blocks.5.norm2.weight as backbone_specific
[rank 0] add param blocks.5.norm2.bias as backbone_specific
[rank 0] add param blocks.5.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.5.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.5.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.5.mlp.fc2.bias as backbone_specific
[rank 0] add param blocks.6.norm1.weight as backbone_specific
[rank 0] add param blocks.6.norm1.bias as backbone_specific
[rank 0] add param blocks.6.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.6.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.6.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.6.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.6.attn.proj.weight as backbone_specific
[rank 0] add param blocks.6.attn.proj.bias as backbone_specific
[rank 0] add param blocks.6.norm2.weight as backbone_specific
[rank 0] add param blocks.6.norm2.bias as backbone_specific
[rank 0] add param blocks.6.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.6.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.6.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.6.mlp.fc2.bias as backbone_specific
[rank 0] add param blocks.7.norm1.weight as backbone_specific
[rank 0] add param blocks.7.norm1.bias as backbone_specific
[rank 0] add param blocks.7.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.7.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.7.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.7.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.7.attn.proj.weight as backbone_specific
[rank 0] add param blocks.7.attn.proj.bias as backbone_specific
[rank 0] add param blocks.7.norm2.weight as backbone_specific
[rank 0] add param blocks.7.norm2.bias as backbone_specific
[rank 0] add param blocks.7.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.7.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.7.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.7.mlp.fc2.bias as backbone_specific
[rank 0] add param blocks.8.norm1.weight as backbone_specific
[rank 0] add param blocks.8.norm1.bias as backbone_specific
[rank 0] add param blocks.8.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.8.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.8.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.8.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.8.attn.proj.weight as backbone_specific
[rank 0] add param blocks.8.attn.proj.bias as backbone_specific
[rank 0] add param blocks.8.norm2.weight as backbone_specific
[rank 0] add param blocks.8.norm2.bias as backbone_specific
[rank 0] add param blocks.8.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.8.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.8.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.8.mlp.fc2.bias as backbone_specific
[rank 0] add param blocks.9.norm1.weight as backbone_specific
[rank 0] add param blocks.9.norm1.bias as backbone_specific
[rank 0] add param blocks.9.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.9.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.9.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.9.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.9.attn.proj.weight as backbone_specific
[rank 0] add param blocks.9.attn.proj.bias as backbone_specific
[rank 0] add param blocks.9.norm2.weight as backbone_specific
[rank 0] add param blocks.9.norm2.bias as backbone_specific
[rank 0] add param blocks.9.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.9.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.9.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.9.mlp.fc2.bias as backbone_specific
[rank 0] add param blocks.10.norm1.weight as backbone_specific
[rank 0] add param blocks.10.norm1.bias as backbone_specific
[rank 0] add param blocks.10.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.10.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.10.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.10.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.10.attn.proj.weight as backbone_specific
[rank 0] add param blocks.10.attn.proj.bias as backbone_specific
[rank 0] add param blocks.10.norm2.weight as backbone_specific
[rank 0] add param blocks.10.norm2.bias as backbone_specific
[rank 0] add param blocks.10.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.10.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.10.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.10.mlp.fc2.bias as backbone_specific
[rank 0] add param blocks.11.norm1.weight as backbone_specific
[rank 0] add param blocks.11.norm1.bias as backbone_specific
[rank 0] add param blocks.11.attn.rel_pos_h as backbone_specific
[rank 0] add param blocks.11.attn.rel_pos_w as backbone_specific
[rank 0] add param blocks.11.attn.qkv.weight as backbone_specific
[rank 0] add param blocks.11.attn.qkv.bias as backbone_specific
[rank 0] add param blocks.11.attn.proj.weight as backbone_specific
[rank 0] add param blocks.11.attn.proj.bias as backbone_specific
[rank 0] add param blocks.11.norm2.weight as backbone_specific
[rank 0] add param blocks.11.norm2.bias as backbone_specific
[rank 0] add param blocks.11.mlp.fc1.weight as backbone_specific
[rank 0] add param blocks.11.mlp.fc1.bias as backbone_specific
[rank 0] add param blocks.11.mlp.fc2.weight as backbone_specific
[rank 0] add param blocks.11.mlp.fc2.bias as backbone_specific
[rank 0] add param norm.weight as backbone_specific
[rank 0] add param norm.bias as backbone_specific
[rank 0] add param deconv_layers.0.weight as decoder_specific
[rank 0] add param deconv_layers.1.weight as decoder_specific
[rank 0] add param deconv_layers.1.bias as decoder_specific
[rank 0] add param deconv_layers.3.weight as decoder_specific
[rank 0] add param deconv_layers.4.weight as decoder_specific
[rank 0] add param deconv_layers.4.bias as decoder_specific
[rank 0] add param final_layer.weight as decoder_specific
[rank 0] add param final_layer.bias as decoder_specific
[rank 2] broadcasting backbone-specific param module.backbone_module.pos_embed	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.patch_embed.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.patch_embed.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.norm1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.norm1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.rel_pos_h	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.rel_pos_w	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.qkv.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.qkv.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.proj.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.proj.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.norm2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.norm2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc1.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc1.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc2.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc2.bias	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.norm.weight	group_idx=3
[rank 2] broadcasting backbone-specific param module.backbone_module.norm.bias	group_idx=3
[rank 2] broadcasting decoder-specific param module.decoder_module.deconv_layers.0.weight	group_idx=5
[rank 2] broadcasting decoder-specific param module.decoder_module.deconv_layers.1.weight	group_idx=5
[rank 2] broadcasting decoder-specific param module.decoder_module.deconv_layers.1.bias	group_idx=5
[rank 2] broadcasting decoder-specific param module.decoder_module.deconv_layers.3.weight	group_idx=5
[rank 2] broadcasting decoder-specific param module.decoder_module.deconv_layers.4.weight	group_idx=5
[rank 2] broadcasting decoder-specific param module.decoder_module.deconv_layers.4.bias	group_idx=5
[rank 2] broadcasting decoder-specific param module.decoder_module.final_layer.weight	group_idx=5
[rank 2] broadcasting decoder-specific param module.decoder_module.final_layer.bias	group_idx=5
model_entry(
  (backbone_module): ViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.027272729203104973)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.054545458406209946)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.08181818574666977)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.10909091681241989)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.13636364042758942)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.16363637149333954)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.19090908765792847)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.2181818187236786)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.2454545497894287)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.27272728085517883)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.30000001192092896)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (neck_module): DoNothing()
  (decoder_module): TopDownSimpleHead(
    (deconv_layers): Sequential(
      (0): ConvTranspose2d(768, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
      (1): LayerNorm()
      (2): ReLU(inplace=True)
      (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
      (4): LayerNorm()
      (5): ReLU(inplace=True)
    )
    (final_layer): Conv2d(256, 17, kernel_size=(1, 1), stride=(1, 1))
  )
)
[rank 0] broadcasting backbone-specific param module.backbone_module.pos_embed	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.patch_embed.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.patch_embed.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.norm1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.norm1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.rel_pos_h	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.rel_pos_w	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.qkv.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.qkv.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.proj.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.proj.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.norm2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.norm2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc1.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc1.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc2.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc2.bias	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.norm.weight	group_idx=3
[rank 0] broadcasting backbone-specific param module.backbone_module.norm.bias	group_idx=3
[rank 0] broadcasting decoder-specific param module.decoder_module.deconv_layers.0.weight	group_idx=5
[rank 0] broadcasting decoder-specific param module.decoder_module.deconv_layers.1.weight	group_idx=5
[rank 0] broadcasting decoder-specific param module.decoder_module.deconv_layers.1.bias	group_idx=5
[rank 0] broadcasting decoder-specific param module.decoder_module.deconv_layers.3.weight	group_idx=5
[rank 0] broadcasting decoder-specific param module.decoder_module.deconv_layers.4.weight	group_idx=5
[rank 0] broadcasting decoder-specific param module.decoder_module.deconv_layers.4.bias	group_idx=5
[rank 0] broadcasting decoder-specific param module.decoder_module.final_layer.weight	group_idx=5
[rank 0] broadcasting decoder-specific param module.decoder_module.final_layer.bias	group_idx=5
[2022-09-26 10:06:53,626][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module 		 module_param_name: pos_embed 		 specification: {'lr': 8e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,628][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.patch_embed.proj 		 module_param_name: weight 		 specification: {'lr': 3.3788108825683594e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,628][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.patch_embed.proj 		 module_param_name: bias 		 specification: {'lr': 3.3788108825683594e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,628][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.norm1 		 module_param_name: weight 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,628][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.norm1 		 module_param_name: bias 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,628][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,629][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,629][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,629][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,629][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.attn.proj 		 module_param_name: weight 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,629][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.attn.proj 		 module_param_name: bias 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,629][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.norm2 		 module_param_name: weight 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,629][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.norm2 		 module_param_name: bias 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,629][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,629][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,630][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,630][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.0.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 4.505081176757812e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,630][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.norm1 		 module_param_name: weight 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,630][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.norm1 		 module_param_name: bias 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,630][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,630][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,630][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,630][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,630][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.attn.proj 		 module_param_name: weight 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,631][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.attn.proj 		 module_param_name: bias 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,631][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.norm2 		 module_param_name: weight 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,631][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.norm2 		 module_param_name: bias 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,631][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,631][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,631][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,631][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.1.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 6.006774902343751e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,631][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.norm1 		 module_param_name: weight 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,631][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.norm1 		 module_param_name: bias 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,632][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,632][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,632][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,632][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,632][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.attn.proj 		 module_param_name: weight 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,632][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.attn.proj 		 module_param_name: bias 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,632][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.norm2 		 module_param_name: weight 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,632][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.norm2 		 module_param_name: bias 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.0}
[2022-09-26 10:06:53,632][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,633][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,633][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,633][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.2.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 8.009033203125e-09, 'weight_decay': 0.1}
[2022-09-26 10:06:53,633][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.norm1 		 module_param_name: weight 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,633][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.norm1 		 module_param_name: bias 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,633][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,633][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,633][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,633][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,634][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.attn.proj 		 module_param_name: weight 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,634][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.attn.proj 		 module_param_name: bias 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,634][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.norm2 		 module_param_name: weight 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,634][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.norm2 		 module_param_name: bias 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,634][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,634][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,634][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,634][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.3.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 1.0678710937500001e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,634][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.norm1 		 module_param_name: weight 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,635][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.norm1 		 module_param_name: bias 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,635][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,635][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,635][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,635][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,635][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.attn.proj 		 module_param_name: weight 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,635][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.attn.proj 		 module_param_name: bias 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,635][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.norm2 		 module_param_name: weight 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,635][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.norm2 		 module_param_name: bias 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,636][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,636][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,636][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,636][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.4.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 1.423828125e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,636][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.norm1 		 module_param_name: weight 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,636][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.norm1 		 module_param_name: bias 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,636][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,636][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,636][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,637][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,637][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.attn.proj 		 module_param_name: weight 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,637][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.attn.proj 		 module_param_name: bias 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,637][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.norm2 		 module_param_name: weight 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,637][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.norm2 		 module_param_name: bias 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,637][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,637][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,637][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,637][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.5.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 1.8984375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,638][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.norm1 		 module_param_name: weight 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,638][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.norm1 		 module_param_name: bias 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,638][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,638][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,638][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,638][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,638][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.attn.proj 		 module_param_name: weight 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,638][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.attn.proj 		 module_param_name: bias 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,638][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.norm2 		 module_param_name: weight 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,639][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.norm2 		 module_param_name: bias 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,639][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,639][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,639][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,639][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.6.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 2.5312500000000002e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,639][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.norm1 		 module_param_name: weight 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,639][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.norm1 		 module_param_name: bias 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,639][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,639][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,640][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,640][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,640][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.attn.proj 		 module_param_name: weight 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,640][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.attn.proj 		 module_param_name: bias 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,640][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.norm2 		 module_param_name: weight 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,640][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.norm2 		 module_param_name: bias 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,640][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,640][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,640][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,641][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.7.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 3.375e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,641][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.norm1 		 module_param_name: weight 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,641][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.norm1 		 module_param_name: bias 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,641][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,641][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,641][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,641][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,641][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.attn.proj 		 module_param_name: weight 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,641][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.attn.proj 		 module_param_name: bias 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,642][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.norm2 		 module_param_name: weight 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,642][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.norm2 		 module_param_name: bias 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,642][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,642][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,642][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,642][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.8.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 4.5e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,642][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.norm1 		 module_param_name: weight 		 specification: {'lr': 6e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,642][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.norm1 		 module_param_name: bias 		 specification: {'lr': 6e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,642][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 6e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,642][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 6e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,643][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 6e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,643][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 6e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,643][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.attn.proj 		 module_param_name: weight 		 specification: {'lr': 6e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,643][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.attn.proj 		 module_param_name: bias 		 specification: {'lr': 6e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,643][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.norm2 		 module_param_name: weight 		 specification: {'lr': 6e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,643][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.norm2 		 module_param_name: bias 		 specification: {'lr': 6e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,643][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 6e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,643][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 6e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,643][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 6e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,644][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.9.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 6e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,644][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.norm1 		 module_param_name: weight 		 specification: {'lr': 8e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,644][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.norm1 		 module_param_name: bias 		 specification: {'lr': 8e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,644][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 8e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,644][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 8e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,644][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 8e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,644][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 8e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,644][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.attn.proj 		 module_param_name: weight 		 specification: {'lr': 8e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,644][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.attn.proj 		 module_param_name: bias 		 specification: {'lr': 8e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,645][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.norm2 		 module_param_name: weight 		 specification: {'lr': 8e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,645][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.norm2 		 module_param_name: bias 		 specification: {'lr': 8e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,645][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 8e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,645][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 8e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,645][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 8e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,645][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.10.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 8e-08, 'weight_decay': 0.1}
[2022-09-26 10:06:53,645][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.norm1 		 module_param_name: weight 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.0}
[2022-09-26 10:06:53,645][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.norm1 		 module_param_name: bias 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.0}
[2022-09-26 10:06:53,645][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.attn 		 module_param_name: rel_pos_h 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.0}
[2022-09-26 10:06:53,646][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.attn 		 module_param_name: rel_pos_w 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.0}
[2022-09-26 10:06:53,646][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.attn.qkv 		 module_param_name: weight 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,646][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.attn.qkv 		 module_param_name: bias 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,646][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.attn.proj 		 module_param_name: weight 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,646][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.attn.proj 		 module_param_name: bias 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,646][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.norm2 		 module_param_name: weight 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.0}
[2022-09-26 10:06:53,646][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.norm2 		 module_param_name: bias 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.0}
[2022-09-26 10:06:53,646][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.mlp.fc1 		 module_param_name: weight 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,646][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.mlp.fc1 		 module_param_name: bias 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,647][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.mlp.fc2 		 module_param_name: weight 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,647][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.blocks.11.mlp.fc2 		 module_param_name: bias 		 specification: {'lr': 1.0666666666666666e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,647][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.norm 		 module_param_name: weight 		 specification: {'lr': 8e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,647][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.backbone_module.norm 		 module_param_name: bias 		 specification: {'lr': 8e-08, 'weight_decay': 0.0}
[2022-09-26 10:06:53,647][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.decoder_module.deconv_layers.0 		 module_param_name: weight 		 specification: {'lr': 1e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,647][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.decoder_module.deconv_layers.1 		 module_param_name: weight 		 specification: {'lr': 1e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,647][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.decoder_module.deconv_layers.1 		 module_param_name: bias 		 specification: {'lr': 1e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,647][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.decoder_module.deconv_layers.3 		 module_param_name: weight 		 specification: {'lr': 1e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,647][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.decoder_module.deconv_layers.4 		 module_param_name: weight 		 specification: {'lr': 1e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,648][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.decoder_module.deconv_layers.4 		 module_param_name: bias 		 specification: {'lr': 1e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,648][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.decoder_module.final_layer 		 module_param_name: weight 		 specification: {'lr': 1e-07, 'weight_decay': 0.1}
[2022-09-26 10:06:53,648][solver_multitask_dev.py][line: 191][    INFO] task_id: 0 	module_name: module.decoder_module.final_layer 		 module_param_name: bias 		 specification: {'lr': 1e-07, 'weight_decay': 0.1}
[rank 3] broadcasting backbone-specific param module.backbone_module.pos_embed	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.patch_embed.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.patch_embed.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.norm1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.qkv.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.norm2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.pos_embed	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.qkv.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.norm2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.norm1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.patch_embed.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.qkv.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.patch_embed.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.norm1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.rel_pos_h	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.qkv.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.norm2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.qkv.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.norm2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.rel_pos_h	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.qkv.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.norm1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.norm1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.qkv.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.norm2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.norm1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.rel_pos_h	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.qkv.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.norm1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.qkv.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.qkv.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.norm1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.norm1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.rel_pos_h	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.norm2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.qkv.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.qkv.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.norm1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.rel_pos_h	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.norm2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.rel_pos_h	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.qkv.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.qkv.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.norm1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.norm1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.rel_pos_h	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.qkv.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.norm2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.norm1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.rel_pos_h	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.qkv.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.norm1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.qkv.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.norm2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.norm1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.rel_pos_h	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.norm1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.qkv.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.qkv.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.norm2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.norm1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.norm1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.norm1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.qkv.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.qkv.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.qkv.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.proj.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.proj.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.norm2.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.norm2.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc1.weight	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.norm.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc1.bias	group_idx=3
[rank 3] broadcasting backbone-specific param module.backbone_module.norm.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc2.weight	group_idx=3
[rank 3] broadcasting decoder-specific param module.decoder_module.deconv_layers.0.weight	group_idx=5
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.norm1.weight	group_idx=3
[rank 3] broadcasting decoder-specific param module.decoder_module.deconv_layers.1.weight	group_idx=5
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.norm1.bias	group_idx=3
[rank 3] broadcasting decoder-specific param module.decoder_module.deconv_layers.1.bias	group_idx=5
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.rel_pos_h	group_idx=3
[rank 3] broadcasting decoder-specific param module.decoder_module.deconv_layers.3.weight	group_idx=5
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.rel_pos_w	group_idx=3
[rank 3] broadcasting decoder-specific param module.decoder_module.deconv_layers.4.weight	group_idx=5
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.qkv.weight	group_idx=3
[rank 3] broadcasting decoder-specific param module.decoder_module.deconv_layers.4.bias	group_idx=5
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.qkv.bias	group_idx=3
[rank 3] broadcasting decoder-specific param module.decoder_module.final_layer.weight	group_idx=5
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.proj.bias	group_idx=3
[rank 3] broadcasting decoder-specific param module.decoder_module.final_layer.bias	group_idx=5
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.norm1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.norm1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.rel_pos_h	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.rel_pos_w	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.qkv.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.qkv.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.proj.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.proj.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.norm2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.norm2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc1.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc1.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc2.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc2.bias	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.norm.weight	group_idx=3
[rank 1] broadcasting backbone-specific param module.backbone_module.norm.bias	group_idx=3
[rank 1] broadcasting decoder-specific param module.decoder_module.deconv_layers.0.weight	group_idx=5
[rank 1] broadcasting decoder-specific param module.decoder_module.deconv_layers.1.weight	group_idx=5
[rank 1] broadcasting decoder-specific param module.decoder_module.deconv_layers.1.bias	group_idx=5
[rank 1] broadcasting decoder-specific param module.decoder_module.deconv_layers.3.weight	group_idx=5
[rank 1] broadcasting decoder-specific param module.decoder_module.deconv_layers.4.weight	group_idx=5
[rank 1] broadcasting decoder-specific param module.decoder_module.deconv_layers.4.bias	group_idx=5
[rank 1] broadcasting decoder-specific param module.decoder_module.final_layer.weight	group_idx=5
[rank 1] broadcasting decoder-specific param module.decoder_module.final_layer.bias	group_idx=5
[rank 0] Recovering from /mnt/lustrenew/chencheng1/expr_files/vitruvian/devL2/L2_samll_setting_pose_FT/checkpoints/coco_pose_lr5e4x08_wd01_backbonebclip_layerdecay_stepLR_classichead_dpr3e1_wowin_LN_udp_50ep___SmallSetting___LSA_10p_small_setting4_add_DGMarket/ckpt_task0_iter_newest.pth.tar, keys=['step', 'backbone_args', 'neck_args', 'decoder_args', 'state_dict', 'optimizer']
[rank 0] ======= loading model state for task 0 ... =======
[rank 0] ======= loading optimizer state for task 0 ... =======
sync_print: rank 2, sampler: rank=2, world_size=4, random_seed=0
sync_print: rank 3, sampler: rank=3, world_size=4, random_seed=0
sync_print: rank 0, sampler: rank=0, world_size=4, random_seed=0
sync_print: rank 1, sampler: rank=1, world_size=4, random_seed=0
[rank 2] >>> sanity check: attempting torch.Tensor(1).cuda(), check task_sp_list if stuck
[rank 2] >>> sanity check: torch.Tensor(1).cuda() passed
[rank 3] >>> sanity check: attempting torch.Tensor(1).cuda(), check task_sp_list if stuck
[rank 3] >>> sanity check: torch.Tensor(1).cuda() passed
[2022-09-26 10:07:02,863][           solver.py][line: 252][    INFO] using new lr scheduler!
[rank 0] >>> sanity check: attempting torch.Tensor(1).cuda(), check task_sp_list if stuck
[rank 0] >>> sanity check: torch.Tensor(1).cuda() passed
[rank 1] >>> sanity check: attempting torch.Tensor(1).cuda(), check task_sp_list if stuck
[rank 1] >>> sanity check: torch.Tensor(1).cuda() passed
[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[rank2] setting worker seed 4
[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[rank0] setting worker seed 0
[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[rank1] setting worker seed 2
[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[rank3] setting worker seed 6
[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[rank3] setting worker seed 7
[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[rank0] setting worker seed 1
[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[rank1] setting worker seed 3
[_init_petrel]-   1  cur: 0.000s, avg(1): 0.000s
[rank2] setting worker seed 5
[2022-09-26 10:11:10,390][           solver.py][line: 548][    INFO] Iter: [46000/47000] 	task0 : cocopose_256x192	Time: 247.433 (ETA:68.73h) (245.668) 	Loss: 0.0007 Prec@1: 0.779 LR: 4.0000000000000015e-06 total_loss: 0.000684465398080647  	max mem: 8034
[2022-09-26 10:11:18,347][           solver.py][line: 548][    INFO] Iter: [46010/47000] 	task0 : cocopose_256x192	Time: 0.804 (ETA:0.22h) (0.014) 	Loss: 0.0006 Prec@1: 0.818 LR: 4.0000000000000015e-06 total_loss: 0.0005841028178110719  	max mem: 8381
[2022-09-26 10:11:26,198][           solver.py][line: 548][    INFO] Iter: [46020/47000] 	task0 : cocopose_256x192	Time: 0.785 (ETA:0.21h) (0.005) 	Loss: 0.0006 Prec@1: 0.816 LR: 4.0000000000000015e-06 total_loss: 0.0005854842020198703  	max mem: 8381
[2022-09-26 10:11:34,071][           solver.py][line: 548][    INFO] Iter: [46030/47000] 	task0 : cocopose_256x192	Time: 0.787 (ETA:0.21h) (0.005) 	Loss: 0.0006 Prec@1: 0.815 LR: 4.0000000000000015e-06 total_loss: 0.0006874600076116621  	max mem: 8381
[2022-09-26 10:11:42,256][           solver.py][line: 548][    INFO] Iter: [46040/47000] 	task0 : cocopose_256x192	Time: 0.815 (ETA:0.22h) (0.007) 	Loss: 0.0006 Prec@1: 0.808 LR: 4.0000000000000015e-06 total_loss: 0.0006777686066925526  	max mem: 8381
[2022-09-26 10:11:50,181][           solver.py][line: 548][    INFO] Iter: [46050/47000] 	task0 : cocopose_256x192	Time: 0.796 (ETA:0.21h) (0.008) 	Loss: 0.0006 Prec@1: 0.809 LR: 4.0000000000000015e-06 total_loss: 0.0006479931762441993  	max mem: 8381
[2022-09-26 10:11:58,143][           solver.py][line: 548][    INFO] Iter: [46060/47000] 	task0 : cocopose_256x192	Time: 0.796 (ETA:0.21h) (0.005) 	Loss: 0.0006 Prec@1: 0.820 LR: 4.0000000000000015e-06 total_loss: 0.0005760642816312611  	max mem: 8381
[2022-09-26 10:12:06,105][           solver.py][line: 548][    INFO] Iter: [46070/47000] 	task0 : cocopose_256x192	Time: 0.796 (ETA:0.21h) (0.005) 	Loss: 0.0006 Prec@1: 0.807 LR: 4.0000000000000015e-06 total_loss: 0.000643150124233216  	max mem: 8381
[2022-09-26 10:12:14,127][           solver.py][line: 548][    INFO] Iter: [46080/47000] 	task0 : cocopose_256x192	Time: 0.802 (ETA:0.20h) (0.005) 	Loss: 0.0006 Prec@1: 0.817 LR: 4.0000000000000015e-06 total_loss: 0.0005830336594954133  	max mem: 8381
[2022-09-26 10:12:22,265][           solver.py][line: 548][    INFO] Iter: [46090/47000] 	task0 : cocopose_256x192	Time: 0.814 (ETA:0.21h) (0.005) 	Loss: 0.0006 Prec@1: 0.813 LR: 4.0000000000000015e-06 total_loss: 0.0006132264388725162  	max mem: 8381
[2022-09-26 10:12:30,317][           solver.py][line: 548][    INFO] Iter: [46100/47000] 	task0 : cocopose_256x192	Time: 0.805 (ETA:0.20h) (0.005) 	Loss: 0.0006 Prec@1: 0.811 LR: 4.0000000000000015e-06 total_loss: 0.0006274793995544314  	max mem: 8381
[2022-09-26 10:12:38,512][           solver.py][line: 548][    INFO] Iter: [46110/47000] 	task0 : cocopose_256x192	Time: 0.818 (ETA:0.20h) (0.006) 	Loss: 0.0006 Prec@1: 0.807 LR: 4.0000000000000015e-06 total_loss: 0.0006162936333566904  	max mem: 8381
[2022-09-26 10:12:46,704][           solver.py][line: 548][    INFO] Iter: [46120/47000] 	task0 : cocopose_256x192	Time: 0.820 (ETA:0.20h) (0.006) 	Loss: 0.0006 Prec@1: 0.829 LR: 4.0000000000000015e-06 total_loss: 0.000587993417866528  	max mem: 8381
[2022-09-26 10:12:54,905][           solver.py][line: 548][    INFO] Iter: [46130/47000] 	task0 : cocopose_256x192	Time: 0.820 (ETA:0.20h) (0.006) 	Loss: 0.0006 Prec@1: 0.814 LR: 4.0000000000000015e-06 total_loss: 0.0005920900730416179  	max mem: 8381
[2022-09-26 10:13:03,088][           solver.py][line: 548][    INFO] Iter: [46140/47000] 	task0 : cocopose_256x192	Time: 0.818 (ETA:0.20h) (0.007) 	Loss: 0.0006 Prec@1: 0.824 LR: 4.0000000000000015e-06 total_loss: 0.0006482780445367098  	max mem: 8381
[2022-09-26 10:13:11,301][           solver.py][line: 548][    INFO] Iter: [46150/47000] 	task0 : cocopose_256x192	Time: 0.821 (ETA:0.19h) (0.005) 	Loss: 0.0006 Prec@1: 0.811 LR: 4.0000000000000015e-06 total_loss: 0.0005765101523138583  	max mem: 8381
[2022-09-26 10:13:19,488][           solver.py][line: 548][    INFO] Iter: [46160/47000] 	task0 : cocopose_256x192	Time: 0.818 (ETA:0.19h) (0.006) 	Loss: 0.0006 Prec@1: 0.807 LR: 4.0000000000000015e-06 total_loss: 0.0005738574545830488  	max mem: 8381
[2022-09-26 10:13:27,683][           solver.py][line: 548][    INFO] Iter: [46170/47000] 	task0 : cocopose_256x192	Time: 0.820 (ETA:0.19h) (0.006) 	Loss: 0.0006 Prec@1: 0.809 LR: 4.0000000000000015e-06 total_loss: 0.0005631441017612815  	max mem: 8381
[2022-09-26 10:13:35,855][           solver.py][line: 548][    INFO] Iter: [46180/47000] 	task0 : cocopose_256x192	Time: 0.817 (ETA:0.19h) (0.006) 	Loss: 0.0006 Prec@1: 0.809 LR: 4.0000000000000015e-06 total_loss: 0.0006217437912710011  	max mem: 8381
[2022-09-26 10:13:44,059][           solver.py][line: 548][    INFO] Iter: [46190/47000] 	task0 : cocopose_256x192	Time: 0.820 (ETA:0.18h) (0.005) 	Loss: 0.0006 Prec@1: 0.809 LR: 4.0000000000000015e-06 total_loss: 0.0006484276382252574  	max mem: 8381
[2022-09-26 10:13:52,256][           solver.py][line: 548][    INFO] Iter: [46200/47000] 	task0 : cocopose_256x192	Time: 0.820 (ETA:0.18h) (0.006) 	Loss: 0.0006 Prec@1: 0.813 LR: 4.0000000000000015e-06 total_loss: 0.0005682160845026374  	max mem: 8381
[2022-09-26 10:14:00,481][           solver.py][line: 548][    INFO] Iter: [46210/47000] 	task0 : cocopose_256x192	Time: 0.822 (ETA:0.18h) (0.006) 	Loss: 0.0006 Prec@1: 0.811 LR: 4.0000000000000015e-06 total_loss: 0.0005854826886206865  	max mem: 8381
[2022-09-26 10:14:08,737][           solver.py][line: 548][    INFO] Iter: [46220/47000] 	task0 : cocopose_256x192	Time: 0.826 (ETA:0.18h) (0.006) 	Loss: 0.0006 Prec@1: 0.824 LR: 4.0000000000000015e-06 total_loss: 0.0006157333264127374  	max mem: 8381
[2022-09-26 10:14:17,038][           solver.py][line: 548][    INFO] Iter: [46230/47000] 	task0 : cocopose_256x192	Time: 0.830 (ETA:0.18h) (0.005) 	Loss: 0.0006 Prec@1: 0.812 LR: 4.0000000000000015e-06 total_loss: 0.0005894717760384083  	max mem: 8381
[2022-09-26 10:14:25,241][           solver.py][line: 548][    INFO] Iter: [46240/47000] 	task0 : cocopose_256x192	Time: 0.820 (ETA:0.17h) (0.005) 	Loss: 0.0006 Prec@1: 0.814 LR: 4.0000000000000015e-06 total_loss: 0.0005964096635580063  	max mem: 8381
[2022-09-26 10:14:33,418][           solver.py][line: 548][    INFO] Iter: [46250/47000] 	task0 : cocopose_256x192	Time: 0.818 (ETA:0.17h) (0.005) 	Loss: 0.0006 Prec@1: 0.810 LR: 4.0000000000000015e-06 total_loss: 0.000599559978581965  	max mem: 8381
[2022-09-26 10:14:41,604][           solver.py][line: 548][    INFO] Iter: [46260/47000] 	task0 : cocopose_256x192	Time: 0.819 (ETA:0.17h) (0.005) 	Loss: 0.0006 Prec@1: 0.814 LR: 4.0000000000000015e-06 total_loss: 0.0006674540345557034  	max mem: 8381
[2022-09-26 10:14:49,830][           solver.py][line: 548][    INFO] Iter: [46270/47000] 	task0 : cocopose_256x192	Time: 0.823 (ETA:0.17h) (0.005) 	Loss: 0.0006 Prec@1: 0.802 LR: 4.0000000000000015e-06 total_loss: 0.000585037749260664  	max mem: 8381
[2022-09-26 10:14:58,028][           solver.py][line: 548][    INFO] Iter: [46280/47000] 	task0 : cocopose_256x192	Time: 0.820 (ETA:0.16h) (0.005) 	Loss: 0.0006 Prec@1: 0.809 LR: 4.0000000000000015e-06 total_loss: 0.0006336364313028753  	max mem: 8381
[2022-09-26 10:15:06,296][           solver.py][line: 548][    INFO] Iter: [46290/47000] 	task0 : cocopose_256x192	Time: 0.826 (ETA:0.16h) (0.006) 	Loss: 0.0006 Prec@1: 0.813 LR: 4.0000000000000015e-06 total_loss: 0.0006103808991611004  	max mem: 8381
[2022-09-26 10:15:14,624][           solver.py][line: 548][    INFO] Iter: [46300/47000] 	task0 : cocopose_256x192	Time: 0.833 (ETA:0.16h) (0.006) 	Loss: 0.0006 Prec@1: 0.815 LR: 4.0000000000000015e-06 total_loss: 0.0006257449858821929  	max mem: 8381
[2022-09-26 10:15:22,877][           solver.py][line: 548][    INFO] Iter: [46310/47000] 	task0 : cocopose_256x192	Time: 0.825 (ETA:0.16h) (0.006) 	Loss: 0.0006 Prec@1: 0.815 LR: 4.0000000000000015e-06 total_loss: 0.0006364398868754506  	max mem: 8381
[2022-09-26 10:15:31,204][           solver.py][line: 548][    INFO] Iter: [46320/47000] 	task0 : cocopose_256x192	Time: 0.833 (ETA:0.16h) (0.006) 	Loss: 0.0006 Prec@1: 0.809 LR: 4.0000000000000015e-06 total_loss: 0.0006915444973856211  	max mem: 8381
[2022-09-26 10:15:39,436][           solver.py][line: 548][    INFO] Iter: [46330/47000] 	task0 : cocopose_256x192	Time: 0.823 (ETA:0.15h) (0.007) 	Loss: 0.0006 Prec@1: 0.817 LR: 4.0000000000000015e-06 total_loss: 0.0005331193096935749  	max mem: 8381
[2022-09-26 10:15:47,723][           solver.py][line: 548][    INFO] Iter: [46340/47000] 	task0 : cocopose_256x192	Time: 0.829 (ETA:0.15h) (0.006) 	Loss: 0.0006 Prec@1: 0.815 LR: 4.0000000000000015e-06 total_loss: 0.0005863344413228333  	max mem: 8381
[2022-09-26 10:15:55,989][           solver.py][line: 548][    INFO] Iter: [46350/47000] 	task0 : cocopose_256x192	Time: 0.827 (ETA:0.15h) (0.006) 	Loss: 0.0006 Prec@1: 0.806 LR: 4.0000000000000015e-06 total_loss: 0.0005672085098922253  	max mem: 8381
[2022-09-26 10:16:04,343][           solver.py][line: 548][    INFO] Iter: [46360/47000] 	task0 : cocopose_256x192	Time: 0.835 (ETA:0.15h) (0.006) 	Loss: 0.0006 Prec@1: 0.828 LR: 4.0000000000000015e-06 total_loss: 0.0005343762459233403  	max mem: 8381
[2022-09-26 10:16:12,581][           solver.py][line: 548][    INFO] Iter: [46370/47000] 	task0 : cocopose_256x192	Time: 0.824 (ETA:0.14h) (0.006) 	Loss: 0.0006 Prec@1: 0.811 LR: 4.0000000000000015e-06 total_loss: 0.0005617710994556546  	max mem: 8381
[2022-09-26 10:16:20,829][           solver.py][line: 548][    INFO] Iter: [46380/47000] 	task0 : cocopose_256x192	Time: 0.825 (ETA:0.14h) (0.006) 	Loss: 0.0006 Prec@1: 0.813 LR: 4.0000000000000015e-06 total_loss: 0.0006644047680310905  	max mem: 8381
[2022-09-26 10:16:29,168][           solver.py][line: 548][    INFO] Iter: [46390/47000] 	task0 : cocopose_256x192	Time: 0.834 (ETA:0.14h) (0.006) 	Loss: 0.0006 Prec@1: 0.810 LR: 4.0000000000000015e-06 total_loss: 0.0005924595752730966  	max mem: 8381
[2022-09-26 10:16:37,407][           solver.py][line: 548][    INFO] Iter: [46400/47000] 	task0 : cocopose_256x192	Time: 0.824 (ETA:0.14h) (0.006) 	Loss: 0.0006 Prec@1: 0.818 LR: 4.0000000000000015e-06 total_loss: 0.0005819728248752654  	max mem: 8381
[2022-09-26 10:16:45,780][           solver.py][line: 548][    INFO] Iter: [46410/47000] 	task0 : cocopose_256x192	Time: 0.837 (ETA:0.14h) (0.006) 	Loss: 0.0006 Prec@1: 0.818 LR: 4.0000000000000015e-06 total_loss: 0.0006328015006147325  	max mem: 8381
[2022-09-26 10:16:54,055][           solver.py][line: 548][    INFO] Iter: [46420/47000] 	task0 : cocopose_256x192	Time: 0.828 (ETA:0.13h) (0.006) 	Loss: 0.0006 Prec@1: 0.819 LR: 4.0000000000000015e-06 total_loss: 0.0005814192118123174  	max mem: 8381
[2022-09-26 10:17:02,336][           solver.py][line: 548][    INFO] Iter: [46430/47000] 	task0 : cocopose_256x192	Time: 0.828 (ETA:0.13h) (0.006) 	Loss: 0.0006 Prec@1: 0.809 LR: 4.0000000000000015e-06 total_loss: 0.0006399831036105752  	max mem: 8381
[2022-09-26 10:17:10,536][           solver.py][line: 548][    INFO] Iter: [46440/47000] 	task0 : cocopose_256x192	Time: 0.820 (ETA:0.13h) (0.006) 	Loss: 0.0006 Prec@1: 0.809 LR: 4.0000000000000015e-06 total_loss: 0.0006089468370191753  	max mem: 8381
[2022-09-26 10:17:18,799][           solver.py][line: 548][    INFO] Iter: [46450/47000] 	task0 : cocopose_256x192	Time: 0.826 (ETA:0.13h) (0.006) 	Loss: 0.0006 Prec@1: 0.810 LR: 4.0000000000000015e-06 total_loss: 0.0005861076642759144  	max mem: 8381
[2022-09-26 10:17:27,111][           solver.py][line: 548][    INFO] Iter: [46460/47000] 	task0 : cocopose_256x192	Time: 0.831 (ETA:0.12h) (0.006) 	Loss: 0.0006 Prec@1: 0.821 LR: 4.0000000000000015e-06 total_loss: 0.0005470627802424133  	max mem: 8381
[2022-09-26 10:17:35,311][           solver.py][line: 548][    INFO] Iter: [46470/47000] 	task0 : cocopose_256x192	Time: 0.820 (ETA:0.12h) (0.006) 	Loss: 0.0006 Prec@1: 0.803 LR: 4.0000000000000015e-06 total_loss: 0.000666849606204778  	max mem: 8381
[2022-09-26 10:17:43,541][           solver.py][line: 548][    INFO] Iter: [46480/47000] 	task0 : cocopose_256x192	Time: 0.823 (ETA:0.12h) (0.006) 	Loss: 0.0006 Prec@1: 0.812 LR: 4.0000000000000015e-06 total_loss: 0.000656012212857604  	max mem: 8381
[2022-09-26 10:17:51,906][           solver.py][line: 548][    INFO] Iter: [46490/47000] 	task0 : cocopose_256x192	Time: 0.836 (ETA:0.12h) (0.006) 	Loss: 0.0006 Prec@1: 0.818 LR: 4.0000000000000015e-06 total_loss: 0.00054264155915007  	max mem: 8381
[2022-09-26 10:18:00,090][           solver.py][line: 548][    INFO] Iter: [46500/47000] 	task0 : cocopose_256x192	Time: 0.818 (ETA:0.11h) (0.006) 	Loss: 0.0006 Prec@1: 0.815 LR: 4.0000000000000015e-06 total_loss: 0.0006071559037081897  	max mem: 8381
[2022-09-26 10:18:08,310][           solver.py][line: 548][    INFO] Iter: [46510/47000] 	task0 : cocopose_256x192	Time: 0.822 (ETA:0.11h) (0.006) 	Loss: 0.0006 Prec@1: 0.823 LR: 4.0000000000000015e-06 total_loss: 0.0005961153074167669  	max mem: 8381
[2022-09-26 10:18:16,608][           solver.py][line: 548][    INFO] Iter: [46520/47000] 	task0 : cocopose_256x192	Time: 0.830 (ETA:0.11h) (0.006) 	Loss: 0.0006 Prec@1: 0.812 LR: 4.0000000000000015e-06 total_loss: 0.0005976607208140194  	max mem: 8381
[2022-09-26 10:18:25,017][           solver.py][line: 548][    INFO] Iter: [46530/47000] 	task0 : cocopose_256x192	Time: 0.841 (ETA:0.11h) (0.005) 	Loss: 0.0006 Prec@1: 0.812 LR: 4.0000000000000015e-06 total_loss: 0.0005950669292360544  	max mem: 8381
[2022-09-26 10:18:33,370][           solver.py][line: 548][    INFO] Iter: [46540/47000] 	task0 : cocopose_256x192	Time: 0.835 (ETA:0.11h) (0.006) 	Loss: 0.0006 Prec@1: 0.816 LR: 4.0000000000000015e-06 total_loss: 0.0005503920838236809  	max mem: 8381
[2022-09-26 10:18:41,740][           solver.py][line: 548][    INFO] Iter: [46550/47000] 	task0 : cocopose_256x192	Time: 0.837 (ETA:0.10h) (0.005) 	Loss: 0.0006 Prec@1: 0.807 LR: 4.0000000000000015e-06 total_loss: 0.0006109641399234533  	max mem: 8381
[2022-09-26 10:18:50,234][           solver.py][line: 548][    INFO] Iter: [46560/47000] 	task0 : cocopose_256x192	Time: 0.849 (ETA:0.10h) (0.006) 	Loss: 0.0006 Prec@1: 0.807 LR: 4.0000000000000015e-06 total_loss: 0.0005765052046626806  	max mem: 8381
[2022-09-26 10:18:58,432][           solver.py][line: 548][    INFO] Iter: [46570/47000] 	task0 : cocopose_256x192	Time: 0.820 (ETA:0.10h) (0.006) 	Loss: 0.0006 Prec@1: 0.807 LR: 4.0000000000000015e-06 total_loss: 0.0005784754175692797  	max mem: 8381
[2022-09-26 10:19:06,810][           solver.py][line: 548][    INFO] Iter: [46580/47000] 	task0 : cocopose_256x192	Time: 0.838 (ETA:0.10h) (0.006) 	Loss: 0.0006 Prec@1: 0.821 LR: 4.0000000000000015e-06 total_loss: 0.0005493204807862639  	max mem: 8381
[2022-09-26 10:19:15,144][           solver.py][line: 548][    INFO] Iter: [46590/47000] 	task0 : cocopose_256x192	Time: 0.833 (ETA:0.09h) (0.006) 	Loss: 0.0006 Prec@1: 0.814 LR: 4.0000000000000015e-06 total_loss: 0.0006541110342368484  	max mem: 8381
[2022-09-26 10:19:23,578][           solver.py][line: 548][    INFO] Iter: [46600/47000] 	task0 : cocopose_256x192	Time: 0.843 (ETA:0.09h) (0.006) 	Loss: 0.0006 Prec@1: 0.823 LR: 4.0000000000000015e-06 total_loss: 0.0006158296018838882  	max mem: 8381
[2022-09-26 10:19:31,815][           solver.py][line: 548][    INFO] Iter: [46610/47000] 	task0 : cocopose_256x192	Time: 0.824 (ETA:0.09h) (0.006) 	Loss: 0.0006 Prec@1: 0.818 LR: 4.0000000000000015e-06 total_loss: 0.0005803480162285268  	max mem: 8381
[2022-09-26 10:19:40,130][           solver.py][line: 548][    INFO] Iter: [46620/47000] 	task0 : cocopose_256x192	Time: 0.831 (ETA:0.09h) (0.006) 	Loss: 0.0006 Prec@1: 0.816 LR: 4.0000000000000015e-06 total_loss: 0.0006409692578017712  	max mem: 8381
[2022-09-26 10:19:48,453][           solver.py][line: 548][    INFO] Iter: [46630/47000] 	task0 : cocopose_256x192	Time: 0.832 (ETA:0.09h) (0.005) 	Loss: 0.0006 Prec@1: 0.806 LR: 4.0000000000000015e-06 total_loss: 0.0006571684498339891  	max mem: 8381
[2022-09-26 10:19:56,804][           solver.py][line: 548][    INFO] Iter: [46640/47000] 	task0 : cocopose_256x192	Time: 0.835 (ETA:0.08h) (0.006) 	Loss: 0.0006 Prec@1: 0.813 LR: 4.0000000000000015e-06 total_loss: 0.000580251682549715  	max mem: 8381
[2022-09-26 10:20:05,226][           solver.py][line: 548][    INFO] Iter: [46650/47000] 	task0 : cocopose_256x192	Time: 0.842 (ETA:0.08h) (0.007) 	Loss: 0.0006 Prec@1: 0.818 LR: 4.0000000000000015e-06 total_loss: 0.0006368403555825353  	max mem: 8381
[2022-09-26 10:20:13,651][           solver.py][line: 548][    INFO] Iter: [46660/47000] 	task0 : cocopose_256x192	Time: 0.843 (ETA:0.08h) (0.007) 	Loss: 0.0006 Prec@1: 0.807 LR: 4.0000000000000015e-06 total_loss: 0.0006492387037724257  	max mem: 8381
[2022-09-26 10:20:21,990][           solver.py][line: 548][    INFO] Iter: [46670/47000] 	task0 : cocopose_256x192	Time: 0.833 (ETA:0.08h) (0.006) 	Loss: 0.0006 Prec@1: 0.810 LR: 4.0000000000000015e-06 total_loss: 0.0006234151078388095  	max mem: 8381
[2022-09-26 10:20:30,425][           solver.py][line: 548][    INFO] Iter: [46680/47000] 	task0 : cocopose_256x192	Time: 0.840 (ETA:0.07h) (0.006) 	Loss: 0.0006 Prec@1: 0.820 LR: 4.0000000000000015e-06 total_loss: 0.0006537154549732804  	max mem: 8381
[2022-09-26 10:20:38,751][           solver.py][line: 548][    INFO] Iter: [46690/47000] 	task0 : cocopose_256x192	Time: 0.836 (ETA:0.07h) (0.010) 	Loss: 0.0006 Prec@1: 0.819 LR: 4.0000000000000015e-06 total_loss: 0.0006670700386166573  	max mem: 8381
[2022-09-26 10:20:47,145][           solver.py][line: 548][    INFO] Iter: [46700/47000] 	task0 : cocopose_256x192	Time: 0.838 (ETA:0.07h) (0.006) 	Loss: 0.0006 Prec@1: 0.816 LR: 4.0000000000000015e-06 total_loss: 0.000533594167791307  	max mem: 8381
[2022-09-26 10:20:55,441][           solver.py][line: 548][    INFO] Iter: [46710/47000] 	task0 : cocopose_256x192	Time: 0.831 (ETA:0.07h) (0.008) 	Loss: 0.0006 Prec@1: 0.813 LR: 4.0000000000000015e-06 total_loss: 0.0006927666254341602  	max mem: 8381
[2022-09-26 10:21:03,798][           solver.py][line: 548][    INFO] Iter: [46720/47000] 	task0 : cocopose_256x192	Time: 0.836 (ETA:0.07h) (0.006) 	Loss: 0.0006 Prec@1: 0.819 LR: 4.0000000000000015e-06 total_loss: 0.0006337173981592059  	max mem: 8381
[2022-09-26 10:21:12,189][           solver.py][line: 548][    INFO] Iter: [46730/47000] 	task0 : cocopose_256x192	Time: 0.839 (ETA:0.06h) (0.007) 	Loss: 0.0006 Prec@1: 0.810 LR: 4.0000000000000015e-06 total_loss: 0.0007051448919810355  	max mem: 8381
[2022-09-26 10:21:20,528][           solver.py][line: 548][    INFO] Iter: [46740/47000] 	task0 : cocopose_256x192	Time: 0.834 (ETA:0.06h) (0.007) 	Loss: 0.0006 Prec@1: 0.813 LR: 4.0000000000000015e-06 total_loss: 0.0005995131214149296  	max mem: 8381
[2022-09-26 10:21:28,822][           solver.py][line: 548][    INFO] Iter: [46750/47000] 	task0 : cocopose_256x192	Time: 0.829 (ETA:0.06h) (0.007) 	Loss: 0.0006 Prec@1: 0.803 LR: 4.0000000000000015e-06 total_loss: 0.0006349679897539318  	max mem: 8381
[2022-09-26 10:21:37,182][           solver.py][line: 548][    INFO] Iter: [46760/47000] 	task0 : cocopose_256x192	Time: 0.836 (ETA:0.06h) (0.006) 	Loss: 0.0006 Prec@1: 0.819 LR: 4.0000000000000015e-06 total_loss: 0.0005492473137564957  	max mem: 8381
[2022-09-26 10:21:45,410][           solver.py][line: 548][    INFO] Iter: [46770/47000] 	task0 : cocopose_256x192	Time: 0.823 (ETA:0.05h) (0.006) 	Loss: 0.0006 Prec@1: 0.809 LR: 4.0000000000000015e-06 total_loss: 0.0006522830226458609  	max mem: 8381
[2022-09-26 10:21:53,773][           solver.py][line: 548][    INFO] Iter: [46780/47000] 	task0 : cocopose_256x192	Time: 0.836 (ETA:0.05h) (0.006) 	Loss: 0.0006 Prec@1: 0.818 LR: 4.0000000000000015e-06 total_loss: 0.000571468030102551  	max mem: 8381
[2022-09-26 10:22:02,014][           solver.py][line: 548][    INFO] Iter: [46790/47000] 	task0 : cocopose_256x192	Time: 0.824 (ETA:0.05h) (0.006) 	Loss: 0.0006 Prec@1: 0.804 LR: 4.0000000000000015e-06 total_loss: 0.0006774679641239345  	max mem: 8381
[2022-09-26 10:22:10,389][           solver.py][line: 548][    INFO] Iter: [46800/47000] 	task0 : cocopose_256x192	Time: 0.835 (ETA:0.05h) (0.007) 	Loss: 0.0006 Prec@1: 0.817 LR: 4.0000000000000015e-06 total_loss: 0.0005727063398808241  	max mem: 8381
[2022-09-26 10:22:18,684][           solver.py][line: 548][    INFO] Iter: [46810/47000] 	task0 : cocopose_256x192	Time: 0.830 (ETA:0.04h) (0.009) 	Loss: 0.0006 Prec@1: 0.811 LR: 4.0000000000000015e-06 total_loss: 0.0006460004369728267  	max mem: 8381
[2022-09-26 10:22:26,950][           solver.py][line: 548][    INFO] Iter: [46820/47000] 	task0 : cocopose_256x192	Time: 0.828 (ETA:0.04h) (0.009) 	Loss: 0.0006 Prec@1: 0.809 LR: 4.0000000000000015e-06 total_loss: 0.00057831039885059  	max mem: 8381
[2022-09-26 10:22:35,232][           solver.py][line: 548][    INFO] Iter: [46830/47000] 	task0 : cocopose_256x192	Time: 0.828 (ETA:0.04h) (0.006) 	Loss: 0.0006 Prec@1: 0.819 LR: 4.0000000000000015e-06 total_loss: 0.0006045561167411506  	max mem: 8381
[2022-09-26 10:22:43,538][           solver.py][line: 548][    INFO] Iter: [46840/47000] 	task0 : cocopose_256x192	Time: 0.831 (ETA:0.04h) (0.007) 	Loss: 0.0006 Prec@1: 0.825 LR: 4.0000000000000015e-06 total_loss: 0.000590115028899163  	max mem: 8381
[2022-09-26 10:22:51,750][           solver.py][line: 548][    INFO] Iter: [46850/47000] 	task0 : cocopose_256x192	Time: 0.821 (ETA:0.03h) (0.006) 	Loss: 0.0006 Prec@1: 0.813 LR: 4.0000000000000015e-06 total_loss: 0.0005904933204874396  	max mem: 8381
[2022-09-26 10:23:00,092][           solver.py][line: 548][    INFO] Iter: [46860/47000] 	task0 : cocopose_256x192	Time: 0.835 (ETA:0.03h) (0.007) 	Loss: 0.0006 Prec@1: 0.821 LR: 4.0000000000000015e-06 total_loss: 0.0005967922625131905  	max mem: 8381
[2022-09-26 10:23:08,550][           solver.py][line: 548][    INFO] Iter: [46870/47000] 	task0 : cocopose_256x192	Time: 0.843 (ETA:0.03h) (0.007) 	Loss: 0.0006 Prec@1: 0.809 LR: 4.0000000000000015e-06 total_loss: 0.0006409373600035906  	max mem: 8381
[2022-09-26 10:23:16,978][           solver.py][line: 548][    INFO] Iter: [46880/47000] 	task0 : cocopose_256x192	Time: 0.846 (ETA:0.03h) (0.010) 	Loss: 0.0006 Prec@1: 0.814 LR: 4.0000000000000015e-06 total_loss: 0.0006407877081073821  	max mem: 8381
[2022-09-26 10:23:25,282][           solver.py][line: 548][    INFO] Iter: [46890/47000] 	task0 : cocopose_256x192	Time: 0.830 (ETA:0.03h) (0.006) 	Loss: 0.0006 Prec@1: 0.816 LR: 4.0000000000000015e-06 total_loss: 0.0005597647395916283  	max mem: 8381
[2022-09-26 10:23:33,726][           solver.py][line: 548][    INFO] Iter: [46900/47000] 	task0 : cocopose_256x192	Time: 0.842 (ETA:0.02h) (0.006) 	Loss: 0.0006 Prec@1: 0.819 LR: 4.0000000000000015e-06 total_loss: 0.0006482863100245595  	max mem: 8381
[2022-09-26 10:23:42,133][           solver.py][line: 548][    INFO] Iter: [46910/47000] 	task0 : cocopose_256x192	Time: 0.843 (ETA:0.02h) (0.009) 	Loss: 0.0006 Prec@1: 0.817 LR: 4.0000000000000015e-06 total_loss: 0.0006345565197989345  	max mem: 8381
[2022-09-26 10:23:50,343][           solver.py][line: 548][    INFO] Iter: [46920/47000] 	task0 : cocopose_256x192	Time: 0.818 (ETA:0.02h) (0.007) 	Loss: 0.0006 Prec@1: 0.823 LR: 4.0000000000000015e-06 total_loss: 0.0006271385936997831  	max mem: 8381
[2022-09-26 10:23:58,576][           solver.py][line: 548][    INFO] Iter: [46930/47000] 	task0 : cocopose_256x192	Time: 0.826 (ETA:0.02h) (0.009) 	Loss: 0.0006 Prec@1: 0.817 LR: 4.0000000000000015e-06 total_loss: 0.000663787592202425  	max mem: 8381
[2022-09-26 10:24:06,892][           solver.py][line: 548][    INFO] Iter: [46940/47000] 	task0 : cocopose_256x192	Time: 0.832 (ETA:0.01h) (0.006) 	Loss: 0.0006 Prec@1: 0.805 LR: 4.0000000000000015e-06 total_loss: 0.0005621889722533524  	max mem: 8381
[2022-09-26 10:24:15,148][           solver.py][line: 548][    INFO] Iter: [46950/47000] 	task0 : cocopose_256x192	Time: 0.826 (ETA:0.01h) (0.007) 	Loss: 0.0006 Prec@1: 0.812 LR: 4.0000000000000015e-06 total_loss: 0.0006338748498819768  	max mem: 8381
[2022-09-26 10:24:23,483][           solver.py][line: 548][    INFO] Iter: [46960/47000] 	task0 : cocopose_256x192	Time: 0.833 (ETA:0.01h) (0.006) 	Loss: 0.0006 Prec@1: 0.812 LR: 4.0000000000000015e-06 total_loss: 0.0006603776128031313  	max mem: 8381
[2022-09-26 10:24:31,739][           solver.py][line: 548][    INFO] Iter: [46970/47000] 	task0 : cocopose_256x192	Time: 0.826 (ETA:0.01h) (0.006) 	Loss: 0.0006 Prec@1: 0.820 LR: 4.0000000000000015e-06 total_loss: 0.0006131448317319155  	max mem: 8381
[2022-09-26 10:24:40,072][           solver.py][line: 548][    INFO] Iter: [46980/47000] 	task0 : cocopose_256x192	Time: 0.833 (ETA:0.00h) (0.006) 	Loss: 0.0006 Prec@1: 0.816 LR: 4.0000000000000015e-06 total_loss: 0.0005748748662881553  	max mem: 8381
[2022-09-26 10:24:48,574][           solver.py][line: 548][    INFO] Iter: [46990/47000] 	task0 : cocopose_256x192	Time: 0.850 (ETA:0.00h) (0.006) 	Loss: 0.0006 Prec@1: 0.805 LR: 4.0000000000000015e-06 total_loss: 0.0006363800494000316  	max mem: 8381
saving to /mnt/lustrenew/chencheng1/expr_files/vitruvian/devL2/L2_samll_setting_pose_FT/checkpoints/coco_pose_lr5e4x08_wd01_backbonebclip_layerdecay_stepLR_classichead_dpr3e1_wowin_LN_udp_50ep___SmallSetting___LSA_10p_small_setting4_add_DGMarket/ckpt_task0_iter_newest.pth.tar
[rank 0000]-[INFO]-[c13d]-[2022-09-26 10:25:09]-[/spring/src/linklink/src/core.cc:260]: linklink finalized!
[rank 0002]-[INFO]-[adbf]-[2022-09-26 10:25:09]-[/spring/src/linklink/src/core.cc:260]: linklink finalized!
[rank 0001]-[INFO]-[d30b]-[2022-09-26 10:25:09]-[/spring/src/linklink/src/core.cc:260]: linklink finalized!
[rank 0003]-[INFO]-[3b5c]-[2022-09-26 10:25:09]-[/spring/src/linklink/src/core.cc:260]: linklink finalized!
2022-09-26 10:25:11 953e1981 INFO: (pavi2.training) SummaryWriter now to close ... Flushing data ...
2022-09-26 10:25:11 78b2a4ac SUCCESS: (pavi2.training) SummaryWriter is successfully closed

PAVI Info ###################################
Training：coco_pose_lr5e4x08_wd01_backbonebclip_layerdecay_stepLR_classichead_dpr3e1_wowin_LN_udp_50ep___SmallSetting___LSA_10p_small_setting4_add_DGMarket
Project：default
Training_id：114570
Training_url：http://autolink.parrots.sensetime.com/pages/content/project/3477/training/114570
Warning: If `Training_url` is not accessible, please upgrade your pavi version.
#############################################

